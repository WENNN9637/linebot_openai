import threading
import openai
import requests
from linebot.models import TextSendMessage

NODE_SERVER_URL = "https://node-mongo-b008.onrender.com"
openai.api_key = "ä½ çš„ OpenAI API Key"  # æˆ–åœ¨ app.py ä¸­è¨­å®šå°±å¯ä»¥çœç•¥

def get_waiting_message(context="answer_feedback"):
    return {
        "answer_feedback": "ä¾†çœ‹çœ‹ä½ ç­”å¾—æ€éº¼æ¨£ ğŸ¤”"
    }.get(context, "ç¨ç­‰ä¸€ä¸‹ï¼Œæˆ‘æƒ³æƒ³çœ‹ ğŸ¤”")

def gpt_push_response(context, user_id, user_text, system_prompt, line_bot_api):
    try:
        response = openai.ChatCompletion.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_text}
            ]
        )
        reply_text = response["choices"][0]["message"]["content"].strip()
        line_bot_api.push_message(user_id, TextSendMessage(text=reply_text))

        # å„²å­˜å›æ‡‰
        requests.post(f"{NODE_SERVER_URL}/save_message", json={
            "user_id": user_id,
            "message_text": "",
            "bot_response": reply_text,
            "message_type": "bot"
        }, timeout=10)

    except Exception as e:
        print(f"âŒ Constructive å›è¦†éŒ¯èª¤ï¼š{e}")
        line_bot_api.push_message(user_id, TextSendMessage(text="å¥½åƒå¡ä½äº†ï¼Œå†å•æˆ‘ä¸€æ¬¡å¥½å—ï¼ŸğŸ¥²"))

def handle_constructive_mode(event, user_id, user_text, line_bot_api):
    wait_msg = get_waiting_message()
    line_bot_api.reply_message(event.reply_token, TextSendMessage(text=wait_msg))

    # åœ¨é€™å€‹æª”æ¡ˆè£¡ä¸éœ€è¦å„²å­˜ user_textï¼Œçµ±ä¸€ç”± app.py è™•ç†


    # é–‹å§‹èƒŒæ™¯å›è¦†
    threading.Thread(
        target=gpt_push_response,
        args=(
            "answer_feedback",
            user_id,
            user_text,
            "ä½ æ˜¯ä¸€ä½æœƒæ ¹æ“šå›ç­”é€²ä¸€æ­¥è¿½å•çš„ C èªè¨€åŠ©æ•™ï¼Œè«‹å…ˆç°¡å–®å›æ‡‰ä½¿ç”¨è€…ï¼Œå†æå‡ºæœ‰æ·±åº¦çš„è¿½å•ã€‚",
            line_bot_api
        )
    ).start()
