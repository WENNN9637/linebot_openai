import re
import threading
import openai
import requests
from linebot.models import TextSendMessage

# === è¨­å®š ===
NODE_SERVER_URL = "https://node-mongo-b008.onrender.com"
openai.api_key = "ä½ çš„ OpenAI API Keyï¼ˆæˆ–ç”¨ app.py è¨­å®šå°±å¯çœç•¥ï¼‰"

# === ğŸ§  ç­‰å¾…èªæç¤º ===
def get_waiting_message(context):
    messages = {
        "answer_feedback": "ä¾†çœ‹çœ‹ä½ ç­”å¾—æ€éº¼æ¨£ ğŸ¤”",
        "explain_answer": "è®“æˆ‘æŸ¥æŸ¥æ­£ç¢ºç­”æ¡ˆæ˜¯ä»€éº¼ ğŸ§",
        "followup_concept": "å¥½å•é¡Œï¼Œæˆ‘ä¾†è§£é‡‹ä¸€ä¸‹ âœï¸",
        "next_question": "ç­‰æˆ‘ç”Ÿä¸€é¡Œæ–°çš„å‡ºä¾† ğŸ¯",
        "general_chat": "æˆ‘æƒ³æƒ³æ€éº¼èªªæ¯”è¼ƒå¥½ ğŸ¤”"
    }
    return messages.get(context, "ç¨ç­‰ä¸€ä¸‹ï¼Œæˆ‘æƒ³æƒ³çœ‹ ğŸ¤”")

# === ğŸ¯ å‡ºé¡Œï¼ˆä¾ç…§é›£åº¦ï¼‰ ===
def generate_active_question(level=1):
    system_message = (
        "ä½ æ˜¯ä¸€ä½ C èªè¨€æ•™å­¸åŠ©æ‰‹ï¼Œæœƒæ ¹æ“šé¡Œç›®é›£åº¦ç”¢ç”ŸæŒ‘æˆ°æ€§å•é¡Œã€‚\n"
        "Level 1ï¼šé¸æ“‡é¡Œï¼ˆç°¡å–®ï¼‰\n"
        "Level 2ï¼šå¡«ç©ºé¡Œï¼ˆä¸­ç­‰ï¼‰\n"
        "Level 3ï¼šç°¡ç­”é¡Œï¼ˆé€²éšï¼‰\n"
        "é€™äº›é›£åº¦è³‡è¨Šåªç”¨æ–¼å…§éƒ¨æ§åˆ¶ï¼Œè«‹å‹¿é¡¯ç¤ºçµ¦ä½¿ç”¨è€…ã€‚\n"
        "å‡ºé¡Œç¯„åœå¾ C èªè¨€åŸºæœ¬èªæ³•ã€è®Šæ•¸ã€æµç¨‹æ§åˆ¶ï¼Œåˆ°é€²éšå¦‚æŒ‡æ¨™èˆ‡è¿´åœˆã€‚"
    )

    user_prompt = (
        f"è«‹ç”¢ç”Ÿä¸€é¡Œ C èªè¨€çš„å•é¡Œï¼Œé›£åº¦ç‚º Level {level}ã€‚\n"
        "è«‹å¾é¸æ“‡é¡Œã€å¡«ç©ºé¡Œã€ç°¡ç­”é¡Œä¸­æ“‡ä¸€ç”¢ç”Ÿï¼Œå¹«åŠ©å­¸ç¿’è€…æ€è€ƒã€‚\n"
        "ä¸è¦æä¾›ç­”æ¡ˆã€‚"
    )

    response = openai.ChatCompletion.create(
        model="gpt-4o",
        messages=[
            {"role": "system", "content": system_message},
            {"role": "user", "content": user_prompt}
        ]
    )
    return response["choices"][0]["message"]["content"].strip()

# === ğŸš€ GPT å›è¦†ä¸¦æ¨é€è¨Šæ¯ï¼ˆèƒŒæ™¯åŸ·è¡Œï¼‰ ===
def gpt_push_response(context, user_id, user_text, system_prompt, line_bot_api, history_messages=None):
    user_prompt = user_text
    if history_messages:
        user_prompt = "\n".join([msg["content"] for msg in history_messages] + [user_text])

    try:
        response = openai.ChatCompletion.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ]
        )
        reply_text = response["choices"][0]["message"]["content"].strip()
        line_bot_api.push_message(user_id, TextSendMessage(text=reply_text))

        # å„²å­˜è¨Šæ¯åˆ° MongoDB
        requests.post(f"{NODE_SERVER_URL}/save_message", json={
            "user_id": user_id,
            "message_text": "",
            "bot_response": reply_text,
            "message_type": "bot"
        }, timeout=10)

    except Exception as e:
        print(f"âŒ GPT å›è¦†å¤±æ•—ï¼š{e}")
        line_bot_api.push_message(user_id, TextSendMessage(text="å“å‘€æˆ‘å¡ä½äº† ğŸ¥² å†å•æˆ‘ä¸€æ¬¡å¥½å—ï¼Ÿ"))

# === ğŸ§  ä¸»å‹•å­¸ç¿’æ¨¡å¼è™•ç†ä¸»å‡½å¼ ===
def handle_active_mode(event, user_id, user_text, user_state, line_bot_api):
    state = user_state.get(user_id, {})
    last_q = state.get("last_question")
    awaiting = state.get("awaiting_answer", False)
    level = state.get("difficulty_level", 1)

    def is_asking_for_answer(user_input):
        return any(kw in user_input.lower() for kw in ["ç­”æ¡ˆ", "æ­£ç¢º", "è§£ç­”", "å‘Šè¨´æˆ‘"])

    def wants_next_question(user_input):
        return any(kw in user_input.lower() for kw in ["ä¸‹ä¸€é¡Œ", "ä¸‹ä¸€å€‹", "å†ä¸€é¡Œ", "è«‹å†çµ¦ä¸€é¡Œ", "å†ä¾†", "ä¸‹ä¸€"])

    def is_answer_related(user_input, question):
        abcd_set = {"a", "b", "c", "d"}
        user_input = user_input.lower().strip()
        if user_input in abcd_set:
            return True
        if re.search(r"(é¸|ç­”æ¡ˆæ˜¯|æ‡‰è©²æ˜¯)[\s]*[a-d]", user_input):
            return True
        keywords = ["printf", "int", "æŒ‡æ¨™", "é™£åˆ—", "return", "è®Šæ•¸"]
        return any(kw in user_input for kw in keywords)

    def is_followup_question(user_input):
        keywords = ["ç‚ºä»€éº¼", "æ˜¯ä»€éº¼", "ä»£è¡¨", "å·®åˆ¥", "æ€éº¼", "å¦‚ä½•", "ä»€éº¼æ„æ€", "è·Ÿ", "æœ‰ä»€éº¼é—œä¿‚"]
        return any(kw in user_input.lower() for kw in keywords)

    if awaiting and last_q:
        if is_asking_for_answer(user_text):
            wait_msg = get_waiting_message("explain_answer")
            line_bot_api.reply_message(event.reply_token, TextSendMessage(text=wait_msg))
            prompt = f"è«‹é‡å°ä»¥ä¸‹ C èªè¨€å•é¡Œçµ¦å‡ºç°¡å–®æ˜ç¢ºçš„è§£é‡‹èˆ‡ç­”æ¡ˆ:\n\nå•é¡Œ:ã€Œ{last_q}ã€"
            threading.Thread(
                target=gpt_push_response,
                args=("explain_answer", user_id, prompt,
                      "ä½ æ˜¯ä¸€ä½ C èªè¨€æ•™å­¸åŠ©ç†ï¼Œè«‹ç”¨ç°¡å–®æ–¹å¼æä¾›æ˜ç¢ºè§£ç­”ã€‚",
                      line_bot_api)
            ).start()
            user_state[user_id].update({
                "awaiting_answer": False,
                "last_question": None,
                "responded": False,
                "irrelevant_count": 0
            })
            return

        elif wants_next_question(user_text):
            question = generate_active_question(level=level)
            wait_msg = get_waiting_message("next_question")
            line_bot_api.reply_message(event.reply_token, TextSendMessage(text=wait_msg))
            line_bot_api.push_message(user_id, TextSendMessage(text=f"Level {level} æ–°æŒ‘æˆ°ä¾†å›‰ï¼\n\n{question}\n\nä½ è¦ºå¾—ç­”æ¡ˆæ˜¯ä»€éº¼ï¼Ÿ"))
            user_state[user_id].update({
                "last_question": question,
                "awaiting_answer": True,
                "responded": False,
                "irrelevant_count": 0
            })
            return

        elif is_answer_related(user_text, last_q):
            wait_msg = get_waiting_message("answer_feedback")
            line_bot_api.reply_message(event.reply_token, TextSendMessage(text=wait_msg))
            prompt = f"""ä»¥ä¸‹æ˜¯ä½ å…ˆå‰å•çš„ C èªè¨€å•é¡Œ:
ã€Œ{last_q}ã€

ä½¿ç”¨è€…å›è¦†:ã€Œ{user_text}ã€

è«‹é‡å°ä»–çš„å›ç­”çµ¦å‡ºå›é¥‹ï¼ˆä¸çµ¦ç­”æ¡ˆï¼‰ï¼Œå¯é¼“å‹µã€ä¿®æ­£éŒ¯èª¤ã€å¼•å°æ€è€ƒã€‚"""
            threading.Thread(
                target=gpt_push_response,
                args=("answer_feedback", user_id, prompt,
                      "ä½ æ˜¯ä¸€ä½ C èªè¨€åŠ©æ•™ï¼Œè«‹é‡å°ä½¿ç”¨è€…çš„å›ç­”é€²è¡Œå»ºè¨­æ€§å›é¥‹ã€‚",
                      line_bot_api)
            ).start()
            user_state[user_id]["responded"] = True
            user_state[user_id]["irrelevant_count"] = 0
            return

        elif is_followup_question(user_text):
            wait_msg = get_waiting_message("followup_concept")
            line_bot_api.reply_message(event.reply_token, TextSendMessage(text=wait_msg))
            followup_prompt = f"""ä½ æ˜¯ä¸€ä½ C èªè¨€æ•™å­¸åŠ©æ•™ã€‚
ç›®å‰ä½¿ç”¨è€…æ­£åœ¨å»¶ä¼¸å•èˆ‡é€™é¡Œæœ‰é—œçš„æ¦‚å¿µ:ã€Œ{user_text}ã€
å•é¡Œæœ¬èº«æ˜¯:ã€Œ{last_q}ã€
è«‹ç”¨ç°¡å–®æ¸…æ¥šçš„æ–¹å¼å›ç­”ä»–ï¼Œä¸è¦æä¾›åŸæœ¬å•é¡Œçš„æ­£ç¢ºè§£ç­”ï¼Œä¹Ÿä¸è¦å‡ºæ–°é¡Œã€‚"""
            threading.Thread(
                target=gpt_push_response,
                args=("followup_concept", user_id, followup_prompt,
                      "ä½ æ˜¯ä¸€ä½ C èªè¨€åŠ©æ•™ï¼Œè«‹ç”¨é¼“å‹µä¸”æ¸…æ¥šçš„æ–¹å¼è§£é‡‹ä½¿ç”¨è€…å»¶ä¼¸è©¢å•çš„æ¦‚å¿µã€‚",
                      line_bot_api)
            ).start()
            user_state[user_id]["irrelevant_count"] = 0
            return

        else:
            count = user_state[user_id].get("irrelevant_count", 0) + 1
            user_state[user_id]["irrelevant_count"] = count

            if user_state[user_id].get("responded") and count >= 2:
                question = generate_active_question(level=level)
                wait_msg = get_waiting_message("next_question")
                line_bot_api.reply_message(event.reply_token, TextSendMessage(text=wait_msg))
                line_bot_api.push_message(user_id, TextSendMessage(text=f"çœ‹èµ·ä¾†é€™é¡Œä½ å·®ä¸å¤šäº†ï¼Œä¾†ä¸€é¡Œæ–°çš„å§ï¼š\n\n{question}\n\nä½ è¦ºå¾—ç­”æ¡ˆæ˜¯ä»€éº¼ï¼Ÿ"))
                user_state[user_id].update({
                    "last_question": question,
                    "awaiting_answer": True,
                    "responded": False,
                    "irrelevant_count": 0
                })
                return
            else:
                line_bot_api.reply_message(event.reply_token, TextSendMessage(text="æˆ‘è¨˜å¾—ä½ é‚„åœ¨é€™é¡Œå–”ï½æƒ³è½ç­”æ¡ˆå¯ä»¥å•æˆ‘ã€Œé€™é¡Œç­”æ¡ˆæ˜¯ä»€éº¼ï¼Ÿã€ï¼›æƒ³ä¸‹ä¸€é¡Œå¯ä»¥èªªã€Œä¸‹ä¸€é¡Œã€ï¼"))
                return

    else:
        question = generate_active_question(level=level)
        wait_msg = get_waiting_message("next_question")
        line_bot_api.reply_message(event.reply_token, TextSendMessage(text=wait_msg))
        line_bot_api.push_message(user_id, TextSendMessage(text=f"ä¾†æŒ‘æˆ°çœ‹çœ‹é€™é¡Œå§ï¼ˆLevel {level}ï¼‰ï¼š\n\n{question}\n\nä½ è¦ºå¾—ç­”æ¡ˆæ˜¯ä»€éº¼ï¼Ÿ"))
        user_state[user_id] = {
            "mode": "active",
            "last_question": question,
            "awaiting_answer": True,
            "responded": False,
            "irrelevant_count": 0,
            "difficulty_level": level
        }
        return
