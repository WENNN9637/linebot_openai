import openai
import requests
import threading
from linebot.models import TextSendMessage

# === ç­‰å¾…æç¤ºèª ===
def get_waiting_message(context="general_chat"):
    return {
        "general_chat": "æˆ‘æƒ³æƒ³æ€éº¼èªªæ¯”è¼ƒå¥½ ğŸ¤”"
    }.get(context, "ç¨ç­‰ä¸€ä¸‹ï¼Œæˆ‘æƒ³æƒ³çœ‹ ğŸ¤”")

# === GPT èƒŒæ™¯å›è¦†æ¨é€ï¼ˆæœ‰è¨˜æ†¶ï¼‰ ===
def gpt_push_response(context, user_id, user_text, system_prompt, line_bot_api, history_messages=None):
    gpt_messages = [{"role": "system", "content": system_prompt}]
    if history_messages:
        gpt_messages += history_messages  # â¬…ï¸ ç”¨ä¾†ä¿ç•™æ­·å²è¨˜æ†¶
    gpt_messages.append({"role": "user", "content": user_text})  # â¬…ï¸ æ–°å•é¡Œæ‰æ˜¯é€™å›åˆçš„é‡é»

    try:
        response = openai.ChatCompletion.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ]
        )
        reply_text = response["choices"][0]["message"]["content"].strip()
        line_bot_api.push_message(user_id, TextSendMessage(text=reply_text))

        requests.post(f"{NODE_SERVER_URL}/save_message", json={
            "user_id": user_id,
            "message_text": "",
            "bot_response": reply_text,
            "message_type": "bot"
        }, timeout=10)

    except Exception as e:
        print(f"âŒ GPT å›è¦†å¤±æ•—ï¼š{e}")
        line_bot_api.push_message(user_id, TextSendMessage(text="å“å‘€æˆ‘å¡ä½äº† ğŸ¥² å†å•æˆ‘ä¸€æ¬¡å¥½å—ï¼Ÿ"))

# === ğŸ—¨ï¸ äº’å‹•å¼æ¨¡å¼è™•ç†ä¸»å‡½å¼ ===
def handle_interactive_mode(event, user_id, user_text, line_bot_api, history):
    # æ­·å²ç°¡åŒ–ï¼ˆåªç•™æœ€è¿‘å¹¾ç­†æœ‰ç”¨å°è©±ï¼‰
    recent = [
        msg for msg in history
        if msg["role"] in ["user", "assistant"]
        and msg["content"].strip() not in ["", "è«‹é¸æ“‡å­¸ç¿’æ¨¡å¼"]
    ]
    short_history = recent[-3:]  # æœ€è¿‘ä¸‰ç­†äº’å‹•

    # å›è¦†ç­‰å¾…èª
    wait_msg = get_waiting_message("general_chat")
    line_bot_api.reply_message(event.reply_token, TextSendMessage(text=wait_msg))

    # åˆ¤æ–·äº’å‹•æƒ…å¢ƒï¼ˆæœªä¾†å¯é€²ä¸€æ­¥åˆ†é¡ï¼‰
    context = "interactive_learning"  # ä½ å¯ä»¥ä¾æ“šæ¨¡å¼åˆ‡æ›ç”¨ä¸åŒ context

    # è¨­è¨ˆ promptï¼ˆå«ä¸»å‹•ã€è¢«å‹•å¼å­¸ç¿’å€åˆ¥ï¼‰
    system_prompt = """
ä½ æ˜¯ä¸€ä½è¦ªåˆ‡ã€æœ‰è€å¿ƒçš„ C èªè¨€å­¸ç¿’åŠ©æ‰‹ï¼Œè§’è‰²åƒæ˜¯ä¸€ä½é™ªä¼´å­¸ç”Ÿè‡ªå­¸çš„æ•™ç·´ã€‚
è«‹æ ¹æ“šä½¿ç”¨è€…çš„è¼¸å…¥åˆ¤æ–·ä»–æ˜¯ä¸»å‹•æå•ï¼Œé‚„æ˜¯éœ€è¦å¼•å°å­¸ç¿’ï¼ˆä¾‹å¦‚ä»Šå¤©è©²è¤‡ç¿’ä»€éº¼ã€å‹•æ‰‹å¯«ç·´ç¿’ï¼‰ã€‚

ğŸŸ¢ è‹¥å­¸ç”Ÿä¸»å‹•æå•ï¼šè«‹ä»¥è¼•é¬†å£èªçš„èªæ°£è§£é‡‹è§€å¿µã€èˆ‰ä¾‹ã€æ­é…ç°¡å–® C èªè¨€ç¨‹å¼ç¢¼ã€‚
    - è§£é‡‹ä¸è¦å¤ªåš´è‚…ï¼Œåƒæ˜¯æœ‹å‹å°è©±ã€‚
    - ç”¨ç”Ÿæ´»æ¯”å–»ä¾†å¹«åŠ©ç†è§£ã€‚
    - æœ€å¾ŒåŠ ä¸€å¥äº’å‹•å•é¡Œï¼šä¾‹å¦‚ã€Œä½ çœ‹å¾—æ‡‚é€™æ®µç¨‹å¼å—ï¼Ÿã€æˆ–ã€Œæƒ³è‡ªå·±æ”¹æ”¹çœ‹å—ï¼Ÿã€

ğŸ”µ è‹¥å­¸ç”Ÿæ²’æœ‰å…·é«”æå•ï¼šè«‹ä½ ä¸»å‹•å‡ºé¡Œæˆ–å®‰æ’å­¸ç¿’ä»»å‹™ã€‚
    - å¯ä»¥æä¸€å€‹ç°¡å–®çš„é¡Œç›®ï¼Œæˆ–è®“å­¸ç”Ÿæ”¹å¯«æŸæ®µ C ç¨‹å¼ç¢¼ã€‚
    - çµ¦ä¸€äº›æç¤ºï¼Œä¸ç”¨ä¸€æ¬¡è¬›å®Œã€‚
    - é¼“å‹µå­¸ç”Ÿå›è¦†ä½ çš„å•é¡Œæˆ–ç·´ç¿’çµæœã€‚

âš ï¸ å›è¦†ä¸è¦å¤ªé•·ï¼Œä¹Ÿä¸è¦ä¸€ä¸‹å­è¬›å¤ªå¤šçŸ¥è­˜ã€‚ä¸€æ­¥ä¸€æ­¥ä¾†ï¼Œå¼•å°å°è©±ã€‚
    """

    # å•Ÿå‹•èƒŒæ™¯ GPT å›è¦†
    threading.Thread(
        target=gpt_push_response,
        args=(context, user_id, user_text, system_prompt, line_bot_api, short_history)
    ).start()
#GPT é¡Œç›®ç”Ÿæˆé‚è¼¯
def generate_daily_challenge_by_gpt(user_level):
    level_description = {
        "beginner": "åˆå­¸è€…ï¼ˆå‰›æ¥è§¸ C èªè¨€ï¼Œé©åˆ if/elseã€è®Šæ•¸ã€è¼¸å…¥è¼¸å‡ºï¼‰",
        "intermediate": "ä¸­éšå­¸ç”Ÿï¼ˆæœƒç”¨é™£åˆ—ã€è¿´åœˆã€å‡½å¼ï¼‰",
        "advanced": "é€²éšå­¸ç”Ÿï¼ˆæ‡‚æŒ‡æ¨™ã€è¨˜æ†¶é«”ç®¡ç†ã€éè¿´ç­‰ï¼‰"
    }

    prompt = f"""
ä½ æ˜¯ä¸€ä½ç†±å¿ƒã€æœ‰è€å¿ƒçš„ C èªè¨€è¬›å¸«ã€‚

è«‹æ ¹æ“šä»¥ä¸‹ç¨‹åº¦èªªæ˜ï¼Œç‚ºå­¸ç”Ÿå‡ºä¸€é¡Œã€Œç•¶æ—¥ç·´ç¿’é¡Œã€ï¼š
- ç¨‹åº¦ï¼š{level_description.get(user_level, 'åˆå­¸è€…')}
- é¡Œç›®é¢¨æ ¼ï¼šæ¸…æ¥šæ˜ç¢ºçš„ä¸­æ–‡æè¿°ï¼Œå¯ä»¥åŠ å…¥ä¸€äº›è¶£å‘³ä¸»é¡Œï¼ˆå¦‚ç”Ÿæ´»åŒ–å°ä»»å‹™ï¼‰
- ä¸éœ€å¤ªé•·ï¼Œä¹Ÿä¸è¦è¶…é 100 å­—
- æœ€å¾ŒåŠ ä¸€å¥é¼“å‹µèªï¼Œä¾‹å¦‚ã€Œå¯«å®Œå¯ä»¥è²¼çµ¦æˆ‘çœ‹çœ‹å“¦ ğŸ‘€ã€æˆ–ã€Œä½ æœƒæ€éº¼å¯«å‘¢ï¼Ÿã€

åªéœ€é¡Œç›®å…§å®¹æœ¬èº«ï¼Œä¸éœ€ç¨‹å¼ç¢¼ã€è§£ç­”æˆ–èªªæ˜ã€‚
"""

    try:
        response = openai.ChatCompletion.create(
            model="gpt-4o",
            messages=[{"role": "system", "content": prompt}]
        )
        question = response.choices[0].message.content.strip()
        return question
    except Exception as e:
        print(f"âŒ ç„¡æ³•ç”Ÿæˆæ¯æ—¥é¡Œç›®ï¼š{e}")
        return "ä»Šå¤©æœ‰é»å¡è»Šï¼Œæ˜å¤©å†ä¾†æŒ‘æˆ°å§ï¼ğŸš§"
#æ¨é€é¡Œç›®
def push_daily_challenge(user_id, user_level, line_bot_api):
    challenge = generate_daily_challenge_by_gpt(user_level)
    intro = f"ğŸŒã€æ¯æ—¥æŒ‘æˆ° - {user_level.upper()}ã€‘\n\n"
    outro = "\n\nå®Œæˆå¾Œå¯ä»¥å›å‚³çµ¦æˆ‘ï¼Œæˆ‘å¹«ä½ çœ‹çœ‹ ğŸ‘"
    
    full_message = intro + challenge + outro
    line_bot_api.push_message(user_id, TextSendMessage(text=full_message))


