import openai
import requests
import threading
import os
from linebot.models import TextSendMessage


# === ç­‰å¾…æç¤ºèª ===
def get_waiting_message(context="general_chat"):
    return {
        "general_chat": "æˆ‘æƒ³æƒ³æ€éº¼èªªæ¯”è¼ƒå¥½ ğŸ¤”"
    }.get(context, "ç¨ç­‰ä¸€ä¸‹ï¼Œæˆ‘æƒ³æƒ³çœ‹ ğŸ¤”")

# === GPT èƒŒæ™¯å›è¦†æ¨é€ï¼ˆæœ‰è¨˜æ†¶ï¼‰ ===
# === æ”¹è‰¯ç‰ˆ GPT èƒŒæ™¯å›è¦†æ¨é€ï¼ˆå«äº’å‹•è¿½è¹¤ï¼‰ ===
import traceback
import time
import os
NODE_SERVER_URL = os.getenv("NODE_SERVER_URL", "https://node-mongo-b008.onrender.com")

def gpt_push_response(context, user_id, user_text, system_prompt, line_bot_api, history_messages=None, retry_count=1):
    try:
        gpt_messages = [{"role": "system", "content": system_prompt}]
        if history_messages:
            cleaned = []
            for msg in history_messages:
                if isinstance(msg, dict) and msg.get("role") in ["user", "assistant"] and msg.get("content"):
                    cleaned.append({"role": msg["role"], "content": msg["content"]})
            gpt_messages += cleaned

        gpt_messages.append({"role": "user", "content": user_text})

        print(f"ğŸ›  [DEBUG] å‘¼å« GPTä¸­ï¼Œè¨Šæ¯æ•¸é‡: {len(gpt_messages)}")
        # åˆ¤æ–·æ˜¯ä¸æ˜¯ã€Œç³»çµ±åˆ‡æ›æ¨¡å¼ã€é¡å‹è¨Šæ¯
        def is_mode_switch_message(text):
            patterns = [
                "mode_",
                "å·²åˆ‡æ›è‡³",
            ]
            return any(pat in text for pat in patterns)

        # ğŸ›  è¨ˆç®—äº’å‹•å›åˆæ•¸
        interaction_rounds = 0
        if history_messages:
            interaction_rounds = len([msg for msg in history_messages if msg.get("role") == "user"])
        interaction_rounds += 1

        # ğŸ›  åˆ¤æ–·å»ºè¨­æ€§è²¢ç»
        constructive_contribution = len(user_text.strip()) > 5

        response = openai.ChatCompletion.create(
            model="gpt-4o",
            messages=gpt_messages,
            timeout=30
        )

        reply_text = response["choices"][0]["message"]["content"].strip()
        print(f"ğŸ›  [DEBUG] GPT å›è¦†å…§å®¹: {reply_text}")

        line_bot_api.push_message(user_id, TextSendMessage(text=reply_text))
        print(f"âœ… [DEBUG] æˆåŠŸæ¨é€åˆ° LINE")

        # ğŸ›  å„²å­˜è¨Šæ¯åˆ°Mongo
        requests.post(f"{NODE_SERVER_URL}/save_message", json={
            "user_id": user_id,
            "message_text": user_text,
            "bot_response": reply_text,
            "message_type": "bot"
            #"interaction_rounds": interaction_rounds,
            #"constructive_contribution": constructive_contribution
        }, timeout=10)
        # ğŸ›  äº’å‹•å®Œæˆå¾Œï¼ŒåŒæ­¥æ›´æ–°user_stats
        # åªæœ‰ç•¶å›è¦†ä¸æ˜¯æ¨¡å¼åˆ‡æ›çš„æ™‚å€™ï¼Œæ‰æ›´æ–°äº’å‹•æ¬¡æ•¸
        if not is_mode_switch_message(user_text) and not is_mode_switch_message(reply_text):
            constructive_contribution = len(user_text.strip()) > 5
            try:
                requests.post(f"{NODE_SERVER_URL}/update_user_stats", json={
                    "user_id": user_id,
                    "constructive": constructive_contribution
                }, timeout=10)
                print(f"âœ… æˆåŠŸæ›´æ–°äº’å‹•æ¬¡æ•¸çµ±è¨ˆ")
            except Exception as e:
                print(f"âŒ æ›´æ–°äº’å‹•æ¬¡æ•¸çµ±è¨ˆå¤±æ•—: {e}")
        else:
            print(f"âš¡ æª¢æ¸¬åˆ°ç³»çµ±æ¨¡å¼è¨Šæ¯ï¼Œä¸åˆ—å…¥äº’å‹•æ¬¡æ•¸")

    except Exception as e:
        import traceback
        traceback.print_exc()
        print(f"âŒ [DEBUG] ç™¼ç”Ÿä¾‹å¤–éŒ¯èª¤ ({type(e).__name__}): {e}")
    

# === ğŸ—¨ï¸ äº’å‹•å¼æ¨¡å¼è™•ç†ä¸»å‡½å¼ ===
# === ğŸ—¨ï¸ æ”¹è‰¯ç‰ˆäº’å‹•å¼æ¨¡å¼è™•ç†ä¸»å‡½å¼ ===
def handle_interactive_mode(event, user_id, user_text, line_bot_api, history):
    # ğŸ›  ä¿®æ­£ç‰ˆï¼šæ­£ç¢ºå»ºæ§‹æœ‰ role çš„æ­·å²è³‡æ–™
    messages = [{"role": "system", "content": "ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„ C èªè¨€å­¸ç¿’åŠ©æ•™ï¼Œæ“…é•·æ ¹æ“šä¸Šä¸‹æ–‡é€²è¡Œå›ç­”ï¼Œé¿å…é‡è¤‡ä¸»é¡Œã€‚"}]
    
    for msg in sorted(history, key=lambda x: x.get("timestamp", "")):
        if msg.get("message_text"):
            messages.append({"role": "user", "content": msg["message_text"]})
        elif msg.get("bot_response"):
            messages.append({"role": "assistant", "content": msg["bot_response"]})

    # ğŸ”¥ é€™æ™‚ messages å°±æ˜¯å®Œæ•´æ­·å²ï¼šæœ‰ userã€æœ‰ bot
    short_history = messages[-4:]  # æœ€è¿‘å››ç­†æœ‰ç”¨äº’å‹•
    
    # é€å‡ºç­‰å¾…æç¤º
    wait_msg = get_waiting_message("general_chat")
    line_bot_api.reply_message(event.reply_token, TextSendMessage(text=wait_msg))

    # åˆ¤æ–·äº’å‹•æƒ…å¢ƒ
    context = "interactive_learning"

    # è¨­è¨ˆæ›´äº’å‹•å¼ prompt
    system_prompt = """
ä½ æ˜¯ä¸€ä½è¦ªåˆ‡ã€æœ‰è€å¿ƒçš„ C èªè¨€å­¸ç¿’æ•™ç·´ï¼Œç›®æ¨™æ˜¯ä¿ƒé€²å­¸ç”Ÿä¸»å‹•å­¸ç¿’å’Œå»ºè¨­æ€§å°è©±ã€‚

ğŸŸ¢ å¦‚æœå­¸ç”Ÿä¸»å‹•æå•ï¼šç°¡å–®è§£é‡‹ + èˆ‰ä¾‹ + æå•ï¼ˆé¼“å‹µå­¸ç”Ÿå»¶ä¼¸è‡ªå·±çš„ä¾‹å­æˆ–æƒ³æ³•ï¼‰
    - èªæ°£è¼•é¬†ï¼Œåƒæœ‹å‹èŠå¤©ã€‚
    - æœ€å¾Œç”¨ä¸€å¥å¼•å°å•é¡Œï¼Œæ¯”å¦‚ï¼šã€Œä½ å¯ä»¥è©¦è‘—å¯«ä¸€å€‹é¡ä¼¼çš„å—ï¼Ÿã€ã€ã€Œé‚£å¦‚æœæ”¹æˆXXXæœƒæ€æ¨£ï¼Ÿã€

ğŸ”µ å¦‚æœå­¸ç”Ÿæ²’æœ‰å…·é«”æå•ï¼šä¸»å‹•çµ¦ä¸€å€‹ç°¡å–®å°æŒ‘æˆ°æˆ–ä¿®æ”¹ä»»å‹™ã€‚
    - é¡Œç›®è¦æœ‰é–‹æ”¾æ€§ï¼Œå¼•å°å­¸ç”Ÿæ€è€ƒä¸åŒåšæ³•ã€‚
    - æ¯æ¬¡åªçµ¦ä¸€é»æç¤ºï¼Œæ ¹æ“šå­¸ç”Ÿå›è¦†èª¿æ•´é›£åº¦ã€‚

âš¡ ç‰¹åˆ¥æ³¨æ„ï¼š
    - å¼•å°å­¸ç”Ÿã€å…·é«”å›ç­”ã€‘ï¼Œä¾‹å¦‚ï¼šè‡ªå·±å¯«ç¨‹å¼ç‰‡æ®µã€èˆ‰ç”Ÿæ´»ä¾‹å­ã€è§£é‡‹è‡ªå·±çš„ç†è§£ã€‚
    - äº’å‹•éç¨‹è¦æœ‰3æ¬¡ä»¥ä¸Šçš„ä¾†å›æ‰ç®—ä¸€æ¬¡å®Œæ•´äº’å‹•ã€‚
    - é‡å°å­¸ç”Ÿå›æ‡‰å…§å®¹ï¼Œçµ¦å‡ºæ­£å‘å›é¥‹æˆ–è¿½å•ç´°ç¯€ã€‚

è«‹ç”¨é€™å€‹äº’å‹•ç­–ç•¥å›æ‡‰å­¸ç”Ÿï¼
    """

    # é–‹èƒŒæ™¯åŸ·è¡Œï¼Œæ¨é€ GPT å›è¦†
    threading.Thread(
        target=gpt_push_response,
        args=(context, user_id, user_text, system_prompt, line_bot_api, short_history)
    ).start()
