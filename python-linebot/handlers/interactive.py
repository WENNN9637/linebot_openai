import openai
import requests
import threading
import os
from linebot.models import TextSendMessage


# === ç­‰å¾…æç¤ºèª ===
def get_waiting_message(context="general_chat"):
    return {
        "general_chat": "æˆ‘æƒ³æƒ³æ€éº¼èªªæ¯”è¼ƒå¥½ ğŸ¤”"
    }.get(context, "ç¨ç­‰ä¸€ä¸‹ï¼Œæˆ‘æƒ³æƒ³çœ‹ ğŸ¤”")

# === GPT èƒŒæ™¯å›è¦†æ¨é€ï¼ˆæœ‰è¨˜æ†¶ï¼‰ ===
# === æ”¹è‰¯ç‰ˆ GPT èƒŒæ™¯å›è¦†æ¨é€ï¼ˆå«äº’å‹•è¿½è¹¤ï¼‰ ===
def gpt_push_response(context, user_id, user_text, system_prompt, line_bot_api, history_messages=None):
    try:
        gpt_messages = [{"role": "system", "content": system_prompt}]
        if history_messages:
            filtered_history = [
                msg for msg in history_messages
                if "å›è²ç¨‹åº" not in msg["content"]
            ]
            gpt_messages += filtered_history

        gpt_messages.append({"role": "user", "content": user_text})

        response = openai.ChatCompletion.create(
            model="gpt-4o",
            messages=gpt_messages
        )
        reply_text = response["choices"][0]["message"]["content"].strip()
        line_bot_api.push_message(user_id, TextSendMessage(text=reply_text))

        # âœ… è¨˜éŒ„äº’å‹•å›åˆæ•¸
        interaction_rounds = len([msg for msg in history_messages if msg["role"] == "user"]) if history_messages else 0
        interaction_rounds += 1  # åŠ ä¸Šé€™ä¸€å›åˆ

        # âœ… åˆ¤æ–·æ˜¯å¦æœ‰å»ºè¨­æ€§è²¢ç»
        constructive_contribution = len(user_text.strip()) > 5  # å›è¦†å…§å®¹è¦æœ‰5å­—ä»¥ä¸Šæ‰ç®—æœ‰å»ºè¨­æ€§ï¼ˆå¯å†ç´°åŒ–åˆ¤æ–·ï¼‰

        # âœ… å„²å­˜äº’å‹•ç´€éŒ„
        try:
            requests.post(f"{NODE_SERVER_URL}/save_message", json={
                "user_id": user_id,
                "message_text": user_text,
                "bot_response": reply_text,
                "message_type": "bot",
                "interaction_rounds": interaction_rounds,
                "constructive_contribution": constructive_contribution
            }, timeout=10)
        except Exception as e:
            print(f"âš ï¸ å„²å­˜è¨Šæ¯å¤±æ•—: {e}")

    except Exception as e:
        print(f"âŒ GPT å›è¦†å¤±æ•—ï¼š{e}")
        line_bot_api.push_message(user_id, TextSendMessage(text="å“å‘€æˆ‘å¡ä½äº† ğŸ¥² å†å•æˆ‘ä¸€æ¬¡å¥½å—ï¼Ÿ"))

# === ğŸ—¨ï¸ äº’å‹•å¼æ¨¡å¼è™•ç†ä¸»å‡½å¼ ===
# === ğŸ—¨ï¸ æ”¹è‰¯ç‰ˆäº’å‹•å¼æ¨¡å¼è™•ç†ä¸»å‡½å¼ ===
def handle_interactive_mode(event, user_id, user_text, line_bot_api, history):
    # ğŸ›  ä¿®æ­£ç‰ˆï¼šæ­£ç¢ºå»ºæ§‹æœ‰ role çš„æ­·å²è³‡æ–™
    messages = [{"role": "system", "content": "ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„ C èªè¨€å­¸ç¿’åŠ©æ•™ï¼Œæ“…é•·æ ¹æ“šä¸Šä¸‹æ–‡é€²è¡Œå›ç­”ï¼Œé¿å…é‡è¤‡ä¸»é¡Œã€‚"}]
    
    for msg in sorted(history.get("messages", []), key=lambda x: x.get("timestamp", "")):
        if msg.get("message_text"):
            messages.append({"role": "user", "content": msg["message_text"]})
        elif msg.get("bot_response"):
            messages.append({"role": "assistant", "content": msg["bot_response"]})

    # ğŸ”¥ é€™æ™‚ messages å°±æ˜¯å®Œæ•´æ­·å²ï¼šæœ‰ userã€æœ‰ bot
    short_history = messages[-4:]  # æœ€è¿‘å››ç­†æœ‰ç”¨äº’å‹•
    
    # é€å‡ºç­‰å¾…æç¤º
    wait_msg = get_waiting_message("general_chat")
    line_bot_api.reply_message(event.reply_token, TextSendMessage(text=wait_msg))

    # åˆ¤æ–·äº’å‹•æƒ…å¢ƒ
    context = "interactive_learning"

    # è¨­è¨ˆæ›´äº’å‹•å¼ prompt
    system_prompt = """
ä½ æ˜¯ä¸€ä½è¦ªåˆ‡ã€æœ‰è€å¿ƒçš„ C èªè¨€å­¸ç¿’æ•™ç·´ï¼Œç›®æ¨™æ˜¯ä¿ƒé€²å­¸ç”Ÿä¸»å‹•å­¸ç¿’å’Œå»ºè¨­æ€§å°è©±ã€‚

ğŸŸ¢ å¦‚æœå­¸ç”Ÿä¸»å‹•æå•ï¼šç°¡å–®è§£é‡‹ + èˆ‰ä¾‹ + æå•ï¼ˆé¼“å‹µå­¸ç”Ÿå»¶ä¼¸è‡ªå·±çš„ä¾‹å­æˆ–æƒ³æ³•ï¼‰
    - èªæ°£è¼•é¬†ï¼Œåƒæœ‹å‹èŠå¤©ã€‚
    - æœ€å¾Œç”¨ä¸€å¥å¼•å°å•é¡Œï¼Œæ¯”å¦‚ï¼šã€Œä½ å¯ä»¥è©¦è‘—å¯«ä¸€å€‹é¡ä¼¼çš„å—ï¼Ÿã€ã€ã€Œé‚£å¦‚æœæ”¹æˆXXXæœƒæ€æ¨£ï¼Ÿã€

ğŸ”µ å¦‚æœå­¸ç”Ÿæ²’æœ‰å…·é«”æå•ï¼šä¸»å‹•çµ¦ä¸€å€‹ç°¡å–®å°æŒ‘æˆ°æˆ–ä¿®æ”¹ä»»å‹™ã€‚
    - é¡Œç›®è¦æœ‰é–‹æ”¾æ€§ï¼Œå¼•å°å­¸ç”Ÿæ€è€ƒä¸åŒåšæ³•ã€‚
    - æ¯æ¬¡åªçµ¦ä¸€é»æç¤ºï¼Œæ ¹æ“šå­¸ç”Ÿå›è¦†èª¿æ•´é›£åº¦ã€‚

âš¡ ç‰¹åˆ¥æ³¨æ„ï¼š
    - å¼•å°å­¸ç”Ÿã€å…·é«”å›ç­”ã€‘ï¼Œä¾‹å¦‚ï¼šè‡ªå·±å¯«ç¨‹å¼ç‰‡æ®µã€èˆ‰ç”Ÿæ´»ä¾‹å­ã€è§£é‡‹è‡ªå·±çš„ç†è§£ã€‚
    - äº’å‹•éç¨‹è¦æœ‰3æ¬¡ä»¥ä¸Šçš„ä¾†å›æ‰ç®—ä¸€æ¬¡å®Œæ•´äº’å‹•ã€‚
    - é‡å°å­¸ç”Ÿå›æ‡‰å…§å®¹ï¼Œçµ¦å‡ºæ­£å‘å›é¥‹æˆ–è¿½å•ç´°ç¯€ã€‚

è«‹ç”¨é€™å€‹äº’å‹•ç­–ç•¥å›æ‡‰å­¸ç”Ÿï¼
    """

    # é–‹èƒŒæ™¯åŸ·è¡Œï¼Œæ¨é€ GPT å›è¦†
    threading.Thread(
        target=gpt_push_response,
        args=(context, user_id, user_text, system_prompt, line_bot_api, short_history)
    ).start()
