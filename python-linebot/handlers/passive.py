import threading
import openai
import requests
from linebot.models import TextSendMessage

NODE_SERVER_URL = "https://node-mongo-b008.onrender.com"
openai.api_key = "ä½ çš„ OpenAI API Key"  # æˆ–ç”¨ app.py ä¸­è¨­å®šå³å¯

def get_waiting_message(context="general_chat"):
    return {
        "general_chat": "æˆ‘æƒ³æƒ³æ€éº¼èªªæ¯”è¼ƒå¥½ ğŸ¤”"
    }.get(context, "ç¨ç­‰ä¸€ä¸‹ï¼Œæˆ‘æƒ³æƒ³çœ‹ ğŸ¤”")

def gpt_push_response(context, user_id, user_text, system_prompt, line_bot_api):
    try:
        response = openai.ChatCompletion.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_text}
            ]
        )
        reply_text = response["choices"][0]["message"]["content"].strip()
        line_bot_api.push_message(user_id, TextSendMessage(text=reply_text))

        # å„²å­˜å›æ‡‰
        requests.post(f"{NODE_SERVER_URL}/save_message", json={
            "user_id": user_id,
            "message_text": "",
            "bot_response": reply_text,
            "message_type": "bot"
        }, timeout=10)

    except Exception as e:
        print(f"âŒ Passive å›è¦†éŒ¯èª¤ï¼š{e}")
        line_bot_api.push_message(user_id, TextSendMessage(text="å“å‘€æˆ‘å¡ä½äº†ï¼Œå†å•ä¸€æ¬¡çœ‹çœ‹ ğŸ¥²"))

def handle_passive_mode(event, user_id, user_text, line_bot_api):
    wait_msg = get_waiting_message()
    line_bot_api.reply_message(event.reply_token, TextSendMessage(text=wait_msg))

    # åœ¨é€™å€‹æª”æ¡ˆè£¡ä¸éœ€è¦å„²å­˜ user_textï¼Œçµ±ä¸€ç”± app.py è™•ç†

    # é–‹å§‹èƒŒæ™¯å›è¦†
    threading.Thread(
        target=gpt_push_response,
        args=(
            "general_chat",
            user_id,
            user_text,
            "ä½ æ˜¯ä¸€ä½å…·æœ‰æ­·å²è¨˜æ†¶çš„ C èªè¨€åŠ©æ•™ï¼Œè«‹è‡ªç„¶å›æ‡‰ã€‚",
            line_bot_api
        )
    ).start()
