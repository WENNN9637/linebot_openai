from flask import Flask, request, abort, jsonify
from linebot import LineBotApi, WebhookHandler
from linebot.exceptions import InvalidSignatureError
from linebot.models import *
import os, openai
import requests
import json

app = Flask(__name__)
line_bot_api = LineBotApi(os.getenv('CHANNEL_ACCESS_TOKEN'))
handler = WebhookHandler(os.getenv('CHANNEL_SECRET'))
openai.api_key = os.getenv('OPENAI_API_KEY')

data = {
    "user_id": "U123456789",
    "message_text": "Hello from Python",
    "message_type": "text"
}

NODE_SERVER_URL = "https://node-mongo-b008.onrender.com"

response = requests.post(f"{NODE_SERVER_URL}/save_message", json=data)
print("ğŸ”¹ é€å‡ºè«‹æ±‚åˆ° Node.js API:", response.status_code, response.text)

@app.route("/webhook", methods=["POST"])
def webhook():
    data = request.json  # å–å¾— LINE å‚³ä¾†çš„è¨Šæ¯
    if not data or "events" not in data:
        return jsonify({"error": "Invalid data"}), 400

    events = data["events"]
    for event in events:
        if event["type"] == "message":
            message_data = {
                "user_id": event["source"]["userId"],
                "message_text": event["message"].get("text", ""),
                "message_type": event["message"]["type"],
            }
            
            # âœ… ç™¼é€è¨Šæ¯åˆ° Node.js å„²å­˜
            response = requests.post(f"{NODE_SERVER_URL}/save_message", json=message_data)
            print("ğŸ“¤ ç™¼é€è‡³ Node.js:", response.status_code, response.text, response.json)

    return jsonify({"status": "success"}), 200


# ç´€éŒ„ä½¿ç”¨è€…çš„å­¸ç¿’æ¨¡å¼
user_mode = {}
@app.route("/health", methods=['GET'])
def health_check():
    return "OK", 200  # è®“ Render çŸ¥é“ä¼ºæœå™¨æ­£å¸¸é‹è¡Œï¼Œä¸è§¸ç™¼ OpenAI API
    
@app.route("/callback", methods=['POST'])
def callback():
    signature = request.headers.get('X-Line-Signature')
    if not signature:
        abort(403)
    body = request.get_data(as_text=True)
    try:
        handler.handle(body, signature)
    except InvalidSignatureError:
        abort(400)
    return 'OK'

# ç•¶ç”¨æˆ¶åŠ å…¥å¥½å‹æ™‚ï¼Œç™¼é€å­¸ç¿’æ¨¡å¼é¸å–®
@handler.add(FollowEvent)
def send_welcome(event):
    user_id = event.source.user_id
    user_mode[user_id] = "passive"  # é è¨­æ¨¡å¼ç‚ºè¢«å‹•æ¨¡å¼
    send_mode_selection(user_id)

def GPT_response(text):
    
    model = "ft:gpt-4o-2024-08-06:personal::B5sbnkYa" if is_c_language(text) else "gpt-4o"
    print(f"ä½¿ç”¨çš„æ¨¡å‹: {model}")  # é¡¯ç¤ºç•¶ä¸‹ä½¿ç”¨çš„æ¨¡å‹ (åœ¨å¾Œå° Log ä¸­)
    response = openai.ChatCompletion.create(
        model=model,
        messages=[
            {"role": "system", "content": "ä½ åªèƒ½ä½¿ç”¨ç¹é«”ä¸­æ–‡æˆ–è‹±æ–‡å›ç­”ã€‚"},
            {"role": "user", "content": text}
        ],
        max_tokens=500,
        timeout=30
    )
        
    last_call_time = time.time()  # æ›´æ–°æœ€å¾Œè«‹æ±‚æ™‚é–“
    return response["choices"][0]["message"]["content"].strip()
    
# é€å‡ºå­¸ç¿’æ¨¡å¼é¸æ“‡çš„ Flex Message
def send_mode_selection(user_id):
    flex_message = FlexSendMessage(
        alt_text="è«‹é¸æ“‡å­¸ç¿’æ¨¡å¼",
        contents={
            "type": "bubble",
            "body": {
                "type": "box",
                "layout": "vertical",
                "contents": [
                    {"type": "text", "text": "è«‹é¸æ“‡å­¸ç¿’æ¨¡å¼", "weight": "bold", "size": "lg"},
                    {"type": "button", "style": "primary", "color": "#1DB446",
                     "action": {"type": "message", "label": "äº’å‹•å¼ (Interactive)", "text": "mode_interactive"}},
                    {"type": "button", "style": "primary", "color": "#FFB74D",
                     "action": {"type": "message", "label": "å»ºæ§‹å¼ (Constructive)", "text": "mode_constructive"}},
                    {"type": "button", "style": "primary", "color": "#42A5F5",
                     "action": {"type": "message", "label": "ä¸»å‹•å¼ (Active)", "text": "mode_active"}},
                    {"type": "button", "style": "primary", "color": "#9E9E9E",
                     "action": {"type": "message", "label": "è¢«å‹•å¼ (Passive)", "text": "mode_passive"}}
                ]
            }
        }
    )
    line_bot_api.push_message(user_id, flex_message)

# ç”¢ç”Ÿä¸»å‹•å­¸ç¿’çš„å•é¡Œ
def generate_active_question():
    prompt = "è«‹ç”¢ç”Ÿä¸€å€‹å…·æœ‰æŒ‘æˆ°æ€§çš„å•é¡Œï¼Œé©åˆè®“å­¸ç¿’è€…æ€è€ƒä¸¦å›ç­”ã€‚å•é¡Œæ‡‰è©²èˆ‡å­¸ç¿’ã€ç§‘æŠ€æˆ–é‚è¼¯æ€è€ƒç›¸é—œã€‚"
    response = openai.ChatCompletion.create(
        model="gpt-4o",
        messages=[{"role": "system", "content": "ä½ æ˜¯ä¸€å€‹æ™ºæ…§å‹å­¸ç¿’åŠ©æ‰‹ï¼Œæœƒä¸»å‹•æå‡ºæœ‰è¶£çš„å•é¡Œä¾†å¹«åŠ©ä½¿ç”¨è€…å­¸ç¿’ã€‚"},
                  {"role": "user", "content": prompt}]
    )
    return response["choices"][0]["message"]["content"]

# ç”¢ç”Ÿäº’å‹•å¼å°è©±
def generate_interactive_response(user_input):
    response = openai.ChatCompletion.create(
        model="gpt-4o",
        messages=[{"role": "system", "content": "ä½ æ˜¯ä¸€å€‹å°è©±å‹å­¸ç¿’åŠ©ç†ï¼Œæœƒæ ¹æ“šä½¿ç”¨è€…çš„å•é¡Œé€²è¡Œäº’å‹•ã€‚"},
                  {"role": "user", "content": user_input}]
    )
    return response["choices"][0]["message"]["content"]

# ç”¢ç”Ÿå¼•å°å¼å•é¡Œ (å»ºæ§‹æ¨¡å¼)
def generate_constructive_prompt(user_input):
    prompt = f"ä½¿ç”¨è€…èªªï¼šã€Œ{user_input}ã€ï¼Œè«‹æ ¹æ“šé€™å€‹å…§å®¹å¼•å°ä½¿ç”¨è€…æä¾›æ›´å…·é«”çš„æƒ³æ³•ï¼Œä¾‹å¦‚è©¢å•ä»–å€‘çš„è§€é»æˆ–ç´°ç¯€ã€‚"
    response = openai.ChatCompletion.create(
        model="gpt-4o",
        messages=[{"role": "system", "content": "ä½ æ˜¯ä¸€å€‹å¼•å°å¼å­¸ç¿’åŠ©æ‰‹ï¼Œæœƒå¹«åŠ©ä½¿ç”¨è€…æ·±å…¥æ€è€ƒã€‚"},
                  {"role": "user", "content": prompt}]
    )
    return response["choices"][0]["message"]["content"]

@handler.add(MessageEvent, message=TextMessage)
def handle_message(event):
    user_id = event.source.user_id
    user_text = event.message.text.strip()

    # æª¢æŸ¥æ˜¯å¦æ˜¯æ¨¡å¼åˆ‡æ›æŒ‡ä»¤
    mode_map = {
        "mode_passive": "passive",
        "mode_active": "active",
        "mode_constructive": "constructive",
        "mode_interactive": "interactive"
    }

    if user_text in mode_map:
        user_mode[user_id] = mode_map[user_text]
        reply_text = f"å·²åˆ‡æ›è‡³ã€{user_text.replace('mode_', '').capitalize()}ã€æ¨¡å¼"
        line_bot_api.reply_message(event.reply_token, TextSendMessage(reply_text))
        return

    # å–å¾—ä½¿ç”¨è€…ç•¶å‰æ¨¡å¼ï¼Œé è¨­ç‚ºè¢«å‹•æ¨¡å¼
    mode = user_mode.get(user_id, "passive")
    print(f"ç”¨æˆ¶ {user_id} çš„ç›®å‰æ¨¡å¼ï¼š{mode}")

    # **è¢«å‹•æ¨¡å¼ (ç­‰ä½¿ç”¨è€…å•å•é¡Œæ‰å›æ‡‰)**
    if mode == "passive":
        response_text = generate_interactive_response(user_text)  # ç„¡æ¢ä»¶ä½¿ç”¨ AI ç”Ÿæˆå›æ‡‰


    # **ä¸»å‹•æ¨¡å¼ (è‡ªå‹•æå•)**
    elif mode == "active":
        new_question = generate_active_question()
        response_text = f"ä¾†æŒ‘æˆ°ä¸€ä¸‹å§ï¼\n\n{new_question}"

    # **å»ºæ§‹æ¨¡å¼ (å¼•å°ä½¿ç”¨è€…æä¾›çœ‹æ³•)**
    elif mode == "constructive":
        if len(user_text) < 10:  # è‹¥ä½¿ç”¨è€…è¼¸å…¥å¤ªçŸ­ï¼Œå…ˆå¼•å°
            response_text = generate_constructive_prompt(user_text)
        else:  # è‹¥è¼¸å…¥è¶³å¤ ï¼Œé€²ä¸€æ­¥è¨è«–
            response_text = f"ä½ å‰›å‰›æåˆ°ï¼šã€Œ{user_text}ã€ï¼Œé€™å¾ˆæœ‰è¶£ï¼æˆ‘å€‘ä¾†æ·±å…¥è¨è«–ä¸€ä¸‹ï¼Œè«‹å•ä½ çš„å…·é«”æƒ³æ³•æ˜¯ä»€éº¼ï¼Ÿ"

    # **äº’å‹•æ¨¡å¼ (é›™å‘å°è©±)**
    elif mode == "interactive":
        response_text = generate_interactive_response(user_text)

    else:
        response_text = "æœªçŸ¥æ¨¡å¼ï¼Œè«‹é‡æ–°é¸æ“‡ã€‚"

    line_bot_api.reply_message(event.reply_token, TextSendMessage(response_text))

if __name__ == "__main__":
    port = int(os.environ.get('PORT', 5000))
    app.run(host='0.0.0.0', port=port)
