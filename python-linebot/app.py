from flask import Flask, request, abort, jsonify
from linebot import LineBotApi, WebhookHandler
from linebot.exceptions import InvalidSignatureError
from linebot.models import *
import os, openai
import requests

app = Flask(__name__)
line_bot_api = LineBotApi(os.getenv('CHANNEL_ACCESS_TOKEN'))
handler = WebhookHandler(os.getenv('CHANNEL_SECRET'))
openai.api_key = os.getenv('OPENAI_API_KEY')
NODE_SERVER_URL = "https://node-mongo-b008.onrender.com"
user_mode = {}

def load_history(user_id):
    url = f"{NODE_SERVER_URL}/get_history"
    try:
        response = requests.get(url, params={"user_id": user_id, "limit": 10}, timeout=10)
        response.raise_for_status()
        data = response.json()
        return data if "messages" in data else {"messages": []}
    except requests.exceptions.RequestException as e:
        print(f"âŒ API è®€å–å¤±æ•—: {e}")
        return {"messages": []}



@app.route("/callback", methods=['POST'])
def callback():
    signature = request.headers.get('X-Line-Signature')
    if not signature:
        abort(403)

    body = request.get_data(as_text=True)
    print("ğŸ“¥ æ”¶åˆ° LINE Webhook:", body)

    try:
        handler.handle(body, signature)
    except InvalidSignatureError:
        print("âŒ LINE ç°½åé©—è­‰å¤±æ•—")
        abort(400)

    # **è§£æ JSON ä¸¦å„²å­˜åˆ° MongoDB**
    data = request.get_json(silent=True)
    if not data or "events" not in data:
        return jsonify({"error": "Invalid data"}), 400

    for event in data["events"]:
        if event["type"] == "message":
            message_data = {
                "user_id": event["source"].get("userId", "Unknown"),
                "message_text": event["message"].get("text", ""),
                "message_type": event["message"].get("type", "unknown")
            }
            print("ğŸ“© LINE è¨Šæ¯:", message_data)

            # **å®‰å…¨åœ°å‚³é€åˆ° Node.js**
            try:
                response = requests.post(f"{NODE_SERVER_URL}/save_message", json=message_data)
                print("ğŸ“¤ ç™¼é€è‡³ Node.js:", response.status_code, response.text)
            except requests.exceptions.RequestException as e:
                print(f"âŒ å„²å­˜å¤±æ•—: {e}")

    return 'OK'

def send_mode_selection(user_id):
    flex_message = FlexSendMessage(
        alt_text="è«‹é¸æ“‡å­¸ç¿’æ¨¡å¼",
        contents={
            "type": "bubble",
            "body": {
                "type": "box",
                "layout": "vertical",
                "contents": [
                    {"type": "text", "text": "è«‹é¸æ“‡å­¸ç¿’æ¨¡å¼", "weight": "bold", "size": "lg"},
                    {"type": "button", "style": "primary", "color": "#1DB446",
                     "action": {"type": "message", "label": "äº’å‹•å¼ (Interactive)", "text": "mode_interactive"}},
                    {"type": "button", "style": "primary", "color": "#FFB74D",
                     "action": {"type": "message", "label": "å»ºæ§‹å¼ (Constructive)", "text": "mode_constructive"}},
                    {"type": "button", "style": "primary", "color": "#42A5F5",
                     "action": {"type": "message", "label": "ä¸»å‹•å¼ (Active)", "text": "mode_active"}},
                    {"type": "button", "style": "primary", "color": "#9E9E9E",
                     "action": {"type": "message", "label": "è¢«å‹•å¼ (Passive)", "text": "mode_passive"}}
                ]
            }
        }
    )
    line_bot_api.push_message(user_id, flex_message)

# ç”¢ç”Ÿä¸»å‹•å­¸ç¿’çš„å•é¡Œ
def generate_active_question():
    prompt = """
ä½ æ˜¯ä¸€ä½ C èªè¨€çš„å­¸ç¿’è¼”å°è€å¸«ï¼Œè«‹ä½ è¨­è¨ˆä¸€å€‹èˆ‡ C èªè¨€ç›¸é—œçš„æŒ‘æˆ°æ€§å•é¡Œï¼Œè®“å­¸ç¿’è€…å¯ä»¥æ€è€ƒä¸¦å˜—è©¦å›ç­”ã€‚å•é¡Œæ‡‰æ¶µè“‹ C èªè¨€çš„æ ¸å¿ƒæ¦‚å¿µï¼Œä¾‹å¦‚ï¼šè¨˜æ†¶é«”ç®¡ç†ã€æŒ‡æ¨™ã€çµæ§‹ã€é™£åˆ—ã€æµç¨‹æ§åˆ¶ã€å‡½å¼ã€æˆ–å­—ä¸²æ“ä½œç­‰ï¼Œé›£åº¦é©ä¸­ï¼Œæœ‰åŠ©æ–¼ç†è§£èªæ³•èˆ‡é‚è¼¯ã€‚

è«‹åªç”¢ç”Ÿå•é¡Œï¼Œä¸è¦é™„åŠ ç­”æ¡ˆã€‚
"""
    response = openai.ChatCompletion.create(
        model="gpt-4o",
        messages=[
            {"role": "system", "content": "ä½ æ˜¯ä¸€å€‹ C èªè¨€æ•™å­¸åŠ©æ‰‹ï¼Œæœƒä¸»å‹•æå‡ºå…·æŒ‘æˆ°æ€§çš„å•é¡Œã€‚"},
            {"role": "user", "content": prompt}
        ]
    )
    return response["choices"][0]["message"]["content"].strip()

# ç”¢ç”Ÿäº’å‹•å¼å°è©±
def generate_interactive_response(user_input):
    response = openai.ChatCompletion.create(
        model="gpt-4o",
        messages=[{"role": "system", "content": "ä½ æ˜¯ä¸€å€‹å°è©±å‹å­¸ç¿’åŠ©ç†ï¼Œæœƒæ ¹æ“šä½¿ç”¨è€…çš„å•é¡Œé€²è¡Œäº’å‹•ã€‚"},
                  {"role": "user", "content": user_input}]
    )
    return response["choices"][0]["message"]["content"]

# ç”¢ç”Ÿå¼•å°å¼å•é¡Œ (å»ºæ§‹æ¨¡å¼)
def generate_constructive_prompt(user_input):
    prompt = f"""ä½¿ç”¨è€…èªªï¼šã€Œ{user_input}ã€
è«‹æ ¹æ“šé€™å¥è©±ï¼Œè¨­è¨ˆä¸€å€‹èƒ½ä¿ƒä½¿ä»–æ·±å…¥æ€è€ƒçš„è¿½å•ï¼Œåƒæ˜¯ï¼šã€Œä½ ç‚ºä»€éº¼é€™æ¨£èªç‚ºï¼Ÿã€ã€ã€Œæœ‰æ²’æœ‰å…¶ä»–å¯èƒ½ï¼Ÿã€ã€ã€Œä½ èƒ½èˆ‰ä¸€å€‹ä¾‹å­å—ï¼Ÿã€ç­‰ã€‚
å•é¡Œæ‡‰è©²å¹«åŠ©ä»–æ›´æ¸…æ¥šè‡ªå·±åœ¨æƒ³ä»€éº¼ã€‚"""
    response = openai.ChatCompletion.create(
        model="gpt-4o",
        messages=[
            {"role": "system", "content": "ä½ æ˜¯ä¸€å€‹å¼•å°å¼å­¸ç¿’åŠ©æ‰‹ï¼Œæ“…é•·å•å•é¡Œä¾†å•Ÿç™¼ä½¿ç”¨è€…æ€è€ƒã€‚"},
            {"role": "user", "content": prompt}
        ]
    )
    return response["choices"][0]["message"]["content"]

def is_c_language(text):
    c_keywords = ["c", "#include", "int ", "void ", "printf(", "return", "malloc", "struct "]
    text = text.lower()  # è½‰æ›ç‚ºå°å¯«ï¼Œé¿å…å¤§å°å¯«ä¸åŒ¹é…
    return any(keyword in text for keyword in c_keywords)

def GPT_response(messages):
    if not isinstance(messages, list) or len(messages) == 0:
        raise ValueError("messages å¿…é ˆæ˜¯ä¸€å€‹åŒ…å«å­—å…¸çš„åˆ—è¡¨")
    if messages[0].get("role") != "system":
        messages.insert(0, {"role": "system", "content": "ä½ åªèƒ½ä½¿ç”¨ç¹é«”ä¸­æ–‡æˆ–è‹±æ–‡å›ç­”ã€‚"})
    model = "ft:gpt-4o-2024-08-06:personal::B5sbnkYa" if is_c_language(messages[-1].get("content", "")) else "gpt-4o"
    print(f"ä½¿ç”¨æ¨¡å‹: {model}")
    response = openai.ChatCompletion.create(
        model=model,
        messages=messages,
        max_tokens=500,
        timeout=30  # é¿å… API è¶…æ™‚
    )
    return response["choices"][0]["message"]["content"].strip()

@handler.add(MessageEvent, message=TextMessage)
def handle_message(event):
    user_id = event.source.user_id
    user_text = event.message.text.strip()
    print(f"ğŸ’¬ æ”¶åˆ°ä¾†è‡ª {user_id} çš„è¨Šæ¯: {user_text}")
    mode_map = {
        "mode_passive": "passive",
        "mode_active": "active",
        "mode_constructive": "constructive",
        "mode_interactive": "interactive"
    }

    if user_text in mode_map:
        user_mode[user_id] = mode_map[user_text]
        
        descriptions = {
            "passive": "ä½ æœƒä»¥é–±è®€ç‚ºä¸»ï¼Œæˆ‘æœƒç›¡é‡ç°¡æ½”åœ°å›ç­”ä½ ï¼Œä¸ä¸»å‹•æå•ã€‚",
            "active": "æˆ‘æœƒçµ¦ä½ ä¸€äº›æŒ‘æˆ°æ€§çš„å•é¡Œï¼Œè®“ä½ ä¸»å‹•æ€è€ƒå’Œä½œç­”ã€‚",
            "constructive": "æˆ‘æœƒæ ¹æ“šä½ çš„å›ç­”ï¼Œé€²ä¸€æ­¥è¿½å•ï¼Œå¹«åŠ©ä½ æ·±åŒ–æƒ³æ³•ã€‚",
            "interactive": "æˆ‘å€‘æœƒåƒæœ‹å‹ä¸€æ¨£å°è©±ï¼Œä¸€èµ·è¨è«–ä¸»é¡Œå’Œè§€é»ã€‚"
        }
    
        mode_key = mode_map[user_text]
        mode_name = user_text.replace("mode_", "").capitalize()
        description = descriptions[mode_key]
    
        # å¦‚æœæ˜¯ä¸»å‹•æ¨¡å¼å°±ç›´æ¥å•ä¸€é¡Œ
        if mode_key == "active":
            question = generate_active_question()
            reply_text = f"âœ… å·²åˆ‡æ›è‡³ã€{mode_name}ã€æ¨¡å¼\n\n{description}\n\nğŸ§  ç¬¬ä¸€é¡Œï¼š{question}\n\nä½ è¦ºå¾—ç­”æ¡ˆæ˜¯ä»€éº¼ï¼Ÿ"
        else:
            reply_text = f"âœ… å·²åˆ‡æ›è‡³ã€{mode_name}ã€æ¨¡å¼\n\n{description}"
    
        line_bot_api.reply_message(event.reply_token, TextSendMessage(reply_text))
        return
    # **ğŸ“Œ å–å¾—ä½¿ç”¨è€…ç•¶å‰æ¨¡å¼ï¼Œé è¨­ç‚ºè¢«å‹•æ¨¡å¼**
    mode = user_mode.get(user_id, "passive")
    print(f"ğŸ›  ç”¨æˆ¶ {user_id} çš„ç›®å‰æ¨¡å¼ï¼š{mode}")

    history = load_history(user_id)
    messages = [{"role": "system", "content": "ä½ æ˜¯ä¸€å€‹æ™ºæ…§åŠ©ç†ï¼Œè«‹è¨˜ä½ä½¿ç”¨è€…çš„å°è©±æ­·å²ã€‚"}]
    for msg in history.get("messages", [])[-10:]:
        if msg.get("message_text") and msg.get("bot_response"):
            messages.append({"role": "user", "content": msg["message_text"]})
            messages.append({"role": "assistant", "content": msg["bot_response"]})
    messages.append({"role": "user", "content": user_text})

    # **ğŸ“Œ æ ¹æ“šæ¨¡å¼ä¾†é¸æ“‡ AI äº’å‹•æ–¹å¼**
    if mode in ["passive", "interactive"]:
        response_text = GPT_response(messages)
    elif mode == "active":
        question = generate_active_question()
        response_text = f"ä¾†æŒ‘æˆ°ä¸€ä¸‹å§ï¼è«‹å˜—è©¦å›ç­”é€™å€‹å•é¡Œï¼š\n\n{question}\n\nä½ è¦ºå¾—ç­”æ¡ˆæ˜¯ä»€éº¼ï¼Ÿ"
    elif mode == "constructive":
        response_text = generate_constructive_prompt(user_text)
    else:
        response_text = "æœªçŸ¥æ¨¡å¼ï¼Œè«‹é‡æ–°é¸æ“‡ã€‚"
        
    line_bot_api.reply_message(event.reply_token, TextSendMessage(response_text))
    if response_text.strip():
        message_data = {"user_id": user_id, "message_text": user_text, "bot_response": response_text, "message_type": "text"}
        try:
            requests.post(f"{NODE_SERVER_URL}/save_message", json=message_data, timeout=10)
            print(f"âœ… æˆåŠŸå„²å­˜å°è©±: {message_data}")
        except requests.exceptions.RequestException as e:
            print(f"âŒ å„²å­˜å°è©±å¤±æ•—: {e}")

if __name__ == "__main__":
    port = int(os.environ.get('PORT', 5000))
    app.run(host='0.0.0.0', port=port)
