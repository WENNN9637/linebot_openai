from flask import Flask, request, abort, jsonify
from linebot import LineBotApi, WebhookHandler
from linebot.exceptions import InvalidSignatureError
from linebot.models import *
import os, openai
import requests

app = Flask(__name__)
line_bot_api = LineBotApi(os.getenv('CHANNEL_ACCESS_TOKEN'))
handler = WebhookHandler(os.getenv('CHANNEL_SECRET'))
openai.api_key = os.getenv('OPENAI_API_KEY')
NODE_SERVER_URL = "https://node-mongo-b008.onrender.com"
user_mode = {}
user_state = {}  # user_id: { "mode": "active", "last_question": "...", "awaiting_answer": True }

def load_history(user_id):
    url = f"{NODE_SERVER_URL}/get_history"
    try:
        response = requests.get(url, params={"user_id": user_id, "limit": 10}, timeout=30)
        response.raise_for_status()
        data = response.json()
        return data if "messages" in data else {"messages": []}
    except requests.exceptions.RequestException as e:
        print(f"âŒ API è®€å–å¤±æ•—: {e}")
        return {"messages": []}



@app.route("/callback", methods=['POST'])
def callback():
    signature = request.headers.get('X-Line-Signature')
    if not signature:
        abort(403)

    body = request.get_data(as_text=True)
    print("ğŸ“¥ æ”¶åˆ° LINE Webhook:", body)

    try:
        handler.handle(body, signature)
    except InvalidSignatureError:
        print("âŒ LINE ç°½åé©—è­‰å¤±æ•—")
        abort(400)

    # **è§£æ JSON ä¸¦å„²å­˜åˆ° MongoDB**
    data = request.get_json(silent=True)
    if not data or "events" not in data:
        return jsonify({"error": "Invalid data"}), 400

    for event in data["events"]:
        if event["type"] == "message":
            message_data = {
                "user_id": event["source"].get("userId", "Unknown"),
                "message_text": event["message"].get("text", ""),
                "message_type": event["message"].get("type", "unknown")
            }
            print("ğŸ“© LINE è¨Šæ¯:", message_data)

            # **å®‰å…¨åœ°å‚³é€åˆ° Node.js**
            """try:
                response = requests.post(f"{NODE_SERVER_URL}/save_message", json=message_data)
                print("ğŸ“¤ ç™¼é€è‡³ Node.js:", response.status_code, response.text)
            except requests.exceptions.RequestException as e:
                print(f"âŒ å„²å­˜å¤±æ•—: {e}")"""

    return 'OK'

def send_mode_selection(user_id):
    flex_message = FlexSendMessage(
        alt_text="è«‹é¸æ“‡å­¸ç¿’æ¨¡å¼",
        contents={
            "type": "bubble",
            "body": {
                "type": "box",
                "layout": "vertical",
                "contents": [
                    {"type": "text", "text": "è«‹é¸æ“‡å­¸ç¿’æ¨¡å¼", "weight": "bold", "size": "lg"},
                    {"type": "button", "style": "primary", "color": "#1DB446",
                     "action": {"type": "message", "label": "äº’å‹•å¼ (Interactive)", "text": "mode_interactive"}},
                    {"type": "button", "style": "primary", "color": "#FFB74D",
                     "action": {"type": "message", "label": "å»ºæ§‹å¼ (Constructive)", "text": "mode_constructive"}},
                    {"type": "button", "style": "primary", "color": "#42A5F5",
                     "action": {"type": "message", "label": "ä¸»å‹•å¼ (Active)", "text": "mode_active"}},
                    {"type": "button", "style": "primary", "color": "#9E9E9E",
                     "action": {"type": "message", "label": "è¢«å‹•å¼ (Passive)", "text": "mode_passive"}}
                ]
            }
        }
    )
    line_bot_api.push_message(user_id, flex_message)

# ç”¢ç”Ÿä¸»å‹•å­¸ç¿’çš„å•é¡Œ
def generate_active_question():
    prompt = """
ä½ æ˜¯ä¸€ä½ C èªè¨€çš„å­¸ç¿’è¼”å°è€å¸«ï¼Œè«‹ä½ è¨­è¨ˆä¸€å€‹èˆ‡ C èªè¨€ç›¸é—œçš„æŒ‘æˆ°æ€§å•é¡Œï¼Œè®“å­¸ç¿’è€…å¯ä»¥æ€è€ƒä¸¦å˜—è©¦å›ç­”ã€‚å•é¡Œæ‡‰æ¶µè“‹ C èªè¨€çš„æ ¸å¿ƒæ¦‚å¿µï¼Œä¾‹å¦‚ï¼šè¨˜æ†¶é«”ç®¡ç†ã€æŒ‡æ¨™ã€çµæ§‹ã€é™£åˆ—ã€æµç¨‹æ§åˆ¶ã€å‡½å¼ã€æˆ–å­—ä¸²æ“ä½œç­‰ï¼Œé›£åº¦é©ä¸­ï¼Œæœ‰åŠ©æ–¼ç†è§£èªæ³•èˆ‡é‚è¼¯ã€‚

è«‹åªç”¢ç”Ÿå•é¡Œï¼Œä¸è¦é™„åŠ ç­”æ¡ˆã€‚
"""
    response = openai.ChatCompletion.create(
        model="gpt-4o",
        messages=[
            {"role": "system", "content": "ä½ æ˜¯ä¸€å€‹ C èªè¨€æ•™å­¸åŠ©æ‰‹ï¼Œæœƒä¸»å‹•æå‡ºå…·æŒ‘æˆ°æ€§çš„å•é¡Œã€‚"},
            {"role": "user", "content": prompt}
        ]
    )
    return response["choices"][0]["message"]["content"].strip()

# ç”¢ç”Ÿäº’å‹•å¼å°è©±
def generate_interactive_response(conversation):
    """
    conversation: List of dicts (e.g., [{"role": "user", "content": "..."}, {"role": "assistant", "content": "..."}])
    """

    system_prompt = """
ä½ æ˜¯ä¸€ä½ç†±å¿ƒã€æœ‰è€å¿ƒçš„ C èªè¨€å­¸ç¿’å¤¥ä¼´ï¼Œæœƒç”¨è‡ªç„¶ã€å£èªçš„æ–¹å¼èˆ‡ä½¿ç”¨è€…äº’å‹•ã€‚

è«‹æ ¹æ“šä½¿ç”¨è€…ã€Œæœ€è¿‘çš„æå•å…§å®¹ã€ï¼Œåšå‡ºæ¸…æ¥šä½†è¼•é¬†çš„å›ç­”ã€‚
å³ä½¿ä¹‹å‰è¬›éæŸå€‹ä¸»é¡Œï¼Œè‹¥ä½¿ç”¨è€…åˆ‡æ›è©±é¡Œï¼Œè«‹å„ªå…ˆå›æ‡‰ã€Œç›®å‰çš„æå•ã€ã€‚

è«‹é¿å…é‡è¤‡ä½¿ç”¨è€…çš„èªå¥ï¼Œç›¡é‡æä¾›å¯¦éš›èªªæ˜ã€æ¯”å–»ã€æˆ–ç°¡å–®çš„ç¨‹å¼ç¢¼ç¯„ä¾‹ã€‚

æœ€å¾Œå¯ä»¥åŠ ä¸Šä¸€å¥åå•ï¼Œå¼•å°ä½¿ç”¨è€…ç¹¼çºŒæ€è€ƒï¼Œä¾‹å¦‚ï¼š
- ä½ æœ‰é‡éé€™æ¨£çš„æƒ…æ³å—ï¼Ÿ
- å¦‚æœæ˜¯ä½ æœƒæ€éº¼å¯«ï¼Ÿ
- é€™æ¨£çš„è¨­è¨ˆä½ è¦ºå¾—æœ‰ä»€éº¼é¢¨éšªï¼Ÿ

è«‹ç”¨åƒæœ‹å‹ä¸€æ¨£èŠå¤©çš„èªæ°£ã€‚
"""

    messages = [{"role": "system", "content": system_prompt}] + conversation

    response = openai.ChatCompletion.create(
        model="gpt-4o",
        messages=messages,
        max_tokens=500,
        timeout=20
    )
    return response["choices"][0]["message"]["content"].strip()


# ç”¢ç”Ÿå¼•å°å¼å•é¡Œ (å»ºæ§‹æ¨¡å¼)
def generate_constructive_prompt(user_input):
    prompt = f"""
ä½¿ç”¨è€…è¼¸å…¥äº†ä»¥ä¸‹å…§å®¹ï¼š

ã€Œ{user_input}ã€

ä½ æ˜¯ C èªè¨€æ•™å­¸åŠ©ç†ï¼Œè«‹æ ¹æ“šé€™æ®µå…§å®¹ï¼Œæå‡ºä¸€å€‹ã€Œå…·å•Ÿç™¼æ€§ã€çš„è¿½å•ï¼Œå¼•å°ä½¿ç”¨è€…ï¼š

- è§£é‡‹è‡ªå·±çš„è§€é»
- è£œå……ç´°ç¯€æˆ–ä¾‹å­
- é€²ä¸€æ­¥æ€è€ƒå…¶ä»–å¯èƒ½æ€§
- æˆ–é‡æ§‹ä»–å‰›å‰›çš„ç†è§£

è«‹åªçµ¦ä¸€å¥å…·é«”ã€è‡ªç„¶çš„è¿½å•ï¼Œä¾‹å¦‚ï¼š
- ä½ é€™æ¨£è¨­è¨ˆçš„åŸå› æ˜¯ä»€éº¼ï¼Ÿ
- æœ‰å…¶ä»–æ–¹å¼å¯ä»¥é”åˆ°åŒæ¨£æ•ˆæœå—ï¼Ÿ
- é€™æ®µç¨‹å¼åœ¨ä»€éº¼æƒ…æ³ä¸‹æœƒå‡ºéŒ¯ï¼Ÿ
"""
    response = openai.ChatCompletion.create(
        model="gpt-4o",
        messages=[
            {"role": "system", "content": "ä½ æ˜¯ä¸€ä½æ“…é•·å¼•å°å­¸ç¿’çš„ C èªè¨€åŠ©æ•™ã€‚"},
            {"role": "user", "content": prompt}
        ]
    )
    return response["choices"][0]["message"]["content"].strip()


def is_c_language(text):
    c_keywords = ["c", "#include", "int ", "void ", "printf(", "return", "malloc", "struct "]
    text = text.lower()  # è½‰æ›ç‚ºå°å¯«ï¼Œé¿å…å¤§å°å¯«ä¸åŒ¹é…
    return any(keyword in text for keyword in c_keywords)

def GPT_response(messages):
    if not isinstance(messages, list) or len(messages) == 0:
        raise ValueError("messages å¿…é ˆæ˜¯ä¸€å€‹åŒ…å«å­—å…¸çš„åˆ—è¡¨")
    if messages[0].get("role") != "system":
        messages.insert(0, {"role": "system", "content": "ä½ åªèƒ½ä½¿ç”¨ç¹é«”ä¸­æ–‡æˆ–è‹±æ–‡å›ç­”ã€‚"})
    model = "ft:gpt-4o-2024-08-06:personal::B5sbnkYa" if is_c_language(messages[-1].get("content", "")) else "gpt-4o"
    print(f"ä½¿ç”¨æ¨¡å‹: {model}")
    response = openai.ChatCompletion.create(
        model=model,
        messages=messages,
        max_tokens=500,
        timeout=30  # é¿å… API è¶…æ™‚
    )
    return response["choices"][0]["message"]["content"].strip()

def is_answer_related(user_input, last_question):
    """åˆ¤æ–·ä½¿ç”¨è€…è¼¸å…¥æ˜¯å¦èˆ‡ä¸Šä¸€é¡Œæœ‰é—œè¯"""
    user_input = user_input.lower()
    keywords = ["ç­”æ¡ˆ", "æ˜¯ä»€éº¼", "ä¸æ‡‚", "ç‚ºä»€éº¼", "æˆ‘è¦ºå¾—", "æˆ‘çŒœ", "å¯èƒ½", "å› ç‚º", "æ‡‰è©²", "å—", "ä¸å¤ªæ‡‚", "å¯ä»¥", "å¹«æˆ‘"]
    return any(kw in user_input for kw in keywords) or is_c_language(user_input)

@handler.add(MessageEvent, message=TextMessage)
def handle_message(event):
    user_id = event.source.user_id
    user_text = event.message.text.strip()
    print(f"ğŸ’¬ æ”¶åˆ°ä¾†è‡ª {user_id} çš„è¨Šæ¯: {user_text}")
    mode_map = {
        "mode_passive": "passive",
        "mode_active": "active",
        "mode_constructive": "constructive",
        "mode_interactive": "interactive"
    }

    if user_text in mode_map:
        user_mode[user_id] = mode_map[user_text]
    
        descriptions = {
            "passive": "ä½ æœƒä»¥é–±è®€ç‚ºä¸»ï¼Œæˆ‘æœƒç›¡é‡ç°¡æ½”åœ°å›ç­”ä½ ï¼Œä¸ä¸»å‹•æå•ã€‚",
            "active": "æˆ‘æœƒçµ¦ä½ ä¸€äº›æŒ‘æˆ°æ€§çš„å•é¡Œï¼Œè®“ä½ ä¸»å‹•æ€è€ƒå’Œä½œç­”ã€‚",
            "constructive": "æˆ‘æœƒæ ¹æ“šä½ çš„å›ç­”ï¼Œé€²ä¸€æ­¥è¿½å•ï¼Œå¹«åŠ©ä½ æ·±åŒ–æƒ³æ³•ã€‚",
            "interactive": "æˆ‘å€‘æœƒåƒæœ‹å‹ä¸€æ¨£å°è©±ï¼Œä¸€èµ·è¨è«–ä¸»é¡Œå’Œè§€é»ã€‚"
        }
    
        mode_key = mode_map[user_text]
        mode_name = user_text.replace("mode_", "").capitalize()
        description = descriptions[mode_key]
    
        if mode_key == "active":
            question = generate_active_question()
            user_state[user_id] = {
                "mode": "active",
                "last_question": question,
                "awaiting_answer": True
            }
            reply_text = f"âœ… å·²åˆ‡æ›è‡³ã€{mode_name}ã€æ¨¡å¼\n\n{description}\n\nç¬¬ä¸€é¡Œï¼š{question}\n\nä½ è¦ºå¾—ç­”æ¡ˆæ˜¯ä»€éº¼ï¼Ÿ"
        else:
            reply_text = f"âœ… å·²åˆ‡æ›è‡³ã€{mode_name}ã€æ¨¡å¼\n\n{description}"
    
        line_bot_api.reply_message(event.reply_token, TextSendMessage(reply_text))
        return

    # **ğŸ“Œ å–å¾—ä½¿ç”¨è€…ç•¶å‰æ¨¡å¼ï¼Œé è¨­ç‚ºè¢«å‹•æ¨¡å¼**
    mode = user_mode.get(user_id, "passive")
    print(f"ç”¨æˆ¶ {user_id} çš„ç›®å‰æ¨¡å¼ï¼š{mode}")

    history = load_history(user_id)
    messages = [{"role": "system", "content": "ä½ æ˜¯ä¸€å€‹æ™ºæ…§åŠ©ç†ï¼Œè«‹è¨˜ä½ä½¿ç”¨è€…çš„å°è©±æ­·å²ã€‚"}]
    
    # å–å¾—æ­·å²å°è©±ï¼ŒæŒ‰æ™‚é–“é †åºçµ„åˆ user å’Œ bot çš„è¨Šæ¯
    for msg in sorted(history.get("messages", []), key=lambda x: x.get("timestamp", "")):
        if msg.get("message_text"):
            messages.append({"role": "user", "content": msg["message_text"]})
        elif msg.get("bot_response"):
            messages.append({"role": "assistant", "content": msg["bot_response"]})


    # **ğŸ“Œ æ ¹æ“šæ¨¡å¼ä¾†é¸æ“‡ AI äº’å‹•æ–¹å¼**
    if mode == "passive":
        response_text = GPT_response(messages)
    elif mode == "interactive":
        # å–æœ€è¿‘ 4 ç­†å°è©±ï¼ˆå«ä½¿ç”¨è€…è¼¸å…¥èˆ‡ AI å›æ‡‰ï¼‰
        recent = [
            msg for msg in messages
            if msg["role"] in ["user", "assistant"] and msg["content"].strip() not in ["", "è«‹é¸æ“‡å­¸ç¿’æ¨¡å¼"]
        ]
        short_history = recent[-3:]  # ç•™ 3 å‰‡æ­·å²ï¼ˆå¤ªå¤šæ²’æ„ç¾©ï¼‰
        short_history.append({"role": "user", "content": user_text})  # ç¾åœ¨è¼¸å…¥å¼·åˆ¶åŠ å…¥
        response_text = generate_interactive_response(short_history)
    
    elif mode == "active":
        state = user_state.get(user_id, {})
        last_q = state.get("last_question")
        awaiting = state.get("awaiting_answer", False)
    
        def is_asking_for_answer(user_input):
            user_input = user_input.lower()
            return any(kw in user_input for kw in ["ç­”æ¡ˆ", "æ­£ç¢º", "è§£ç­”", "å‘Šè¨´æˆ‘"])
    
        def wants_next_question(user_input):
            user_input = user_input.lower()
            return any(kw in user_input for kw in ["ä¸‹ä¸€é¡Œ", "ä¸‹ä¸€å€‹", "å†ä¸€é¡Œ", "è«‹å†çµ¦ä¸€é¡Œ", "å†ä¾†", "ä¸‹ä¸€"])
    
        if awaiting and last_q:
            if is_asking_for_answer(user_text):
                # ä½¿ç”¨è€…å•ç­”æ¡ˆï¼Œå›è¦†ä¸¦æ¸…é™¤ç‹€æ…‹
                answer_prompt = f"""è«‹é‡å°ä»¥ä¸‹ C èªè¨€å•é¡Œçµ¦å‡ºç°¡å–®æ˜ç¢ºçš„è§£é‡‹èˆ‡ç­”æ¡ˆï¼š
    
    å•é¡Œï¼šã€Œ{last_q}ã€
    """
                response = openai.ChatCompletion.create(
                    model="gpt-4o",
                    messages=[
                        {"role": "system", "content": "ä½ æ˜¯ä¸€ä½ C èªè¨€æ•™å­¸åŠ©ç†ï¼Œè«‹ç”¨ç°¡å–®æ–¹å¼æä¾›æ˜ç¢ºè§£ç­”ã€‚"},
                        {"role": "user", "content": answer_prompt}
                    ]
                )
                response_text = response["choices"][0]["message"]["content"].strip()
                user_state[user_id]["awaiting_answer"] = False
                user_state[user_id]["last_question"] = None
                user_state[user_id]["responded"] = False
                user_state[user_id]["irrelevant_count"] = 0
    
            elif wants_next_question(user_text):
                # ä½¿ç”¨è€…è¦æ±‚ä¸‹ä¸€é¡Œ
                question = generate_active_question()
                response_text = f"æ–°æŒ‘æˆ°ä¾†å›‰ï¼\n\n{question}\n\nä½ è¦ºå¾—ç­”æ¡ˆæ˜¯ä»€éº¼ï¼Ÿ"
                user_state[user_id] = {
                    "mode": "active",
                    "last_question": question,
                    "awaiting_answer": True,
                    "responded": False,
                    "irrelevant_count": 0
                }
    
            elif is_answer_related(user_text, last_q):
                # ä½¿ç”¨è€…åœ¨å›æ‡‰ç•¶å‰å•é¡Œ
                answer_prompt = f"""ä»¥ä¸‹æ˜¯ä½ å…ˆå‰å•çš„ C èªè¨€å•é¡Œï¼š
    ã€Œ{last_q}ã€
    
    ä½¿ç”¨è€…å›è¦†ï¼šã€Œ{user_text}ã€
    
    è«‹é‡å°ä»–çš„å›ç­”çµ¦å‡ºå›é¥‹ï¼ˆä¸çµ¦ç­”æ¡ˆï¼‰ï¼Œå¯é¼“å‹µã€ä¿®æ­£éŒ¯èª¤ã€å¼•å°æ€è€ƒã€‚
    """
                response = openai.ChatCompletion.create(
                    model="gpt-4o",
                    messages=[
                        {"role": "system", "content": "ä½ æ˜¯ä¸€ä½ C èªè¨€åŠ©æ•™ï¼Œè«‹é‡å°ä½¿ç”¨è€…çš„å›ç­”é€²è¡Œå»ºè¨­æ€§å›é¥‹ã€‚"},
                        {"role": "user", "content": answer_prompt}
                    ]
                )
                response_text = response["choices"][0]["message"]["content"].strip()
                user_state[user_id]["responded"] = True  # âœ… æ¨™è¨˜å·²å›æ‡‰ï¼ˆä½†ä¸æ¸…é™¤ last_questionï¼‰
                user_state[user_id]["irrelevant_count"] = 0  # å›æ‡‰æ­£ç¢ºï¼Œæ¸…é™¤å™ªéŸ³è¨ˆæ•¸
    
            else:
                # ç„¡é—œè¼¸å…¥ï¼šå¦‚æœå·²ç¶“å›ç­”éï¼Œçµ¦å…©æ¬¡æ©Ÿæœƒæ‰è·³é¡Œ
                count = user_state[user_id].get("irrelevant_count", 0) + 1
                user_state[user_id]["irrelevant_count"] = count
    
                if user_state[user_id].get("responded") and count >= 2:
                    question = generate_active_question()
                    response_text = f"çœ‹èµ·ä¾†é€™é¡Œä½ å·®ä¸å¤šäº†ï¼Œä¾†ä¸€é¡Œæ–°çš„å§ï¼š\n\n{question}\n\nä½ è¦ºå¾—ç­”æ¡ˆæ˜¯ä»€éº¼ï¼Ÿ"
                    user_state[user_id] = {
                        "mode": "active",
                        "last_question": question,
                        "awaiting_answer": True,
                        "responded": False,
                        "irrelevant_count": 0
                    }
                else:
                    response_text = "æˆ‘è¨˜å¾—ä½ é‚„åœ¨é€™é¡Œå–”ï½æƒ³è½ç­”æ¡ˆå¯ä»¥å•æˆ‘ã€Œé€™é¡Œç­”æ¡ˆæ˜¯ä»€éº¼ï¼Ÿã€ï¼›æƒ³ä¸‹ä¸€é¡Œå¯ä»¥èªªã€Œä¸‹ä¸€é¡Œã€ï¼"
    
        else:
            # æ²’æœ‰é¡Œç›®åœ¨ç­‰ï¼Œç”¨æˆ¶å‰›é€²ä¾†æˆ–ä¸»å‹•é€²å…¥ activeï¼Œå‡ºæ–°é¡Œ
            question = generate_active_question()
            response_text = f"ä¾†æŒ‘æˆ°çœ‹çœ‹é€™é¡Œå§ï¼š\n\n{question}\n\nä½ è¦ºå¾—ç­”æ¡ˆæ˜¯ä»€éº¼ï¼Ÿ"
            user_state[user_id] = {
                "mode": "active",
                "last_question": question,
                "awaiting_answer": True,
                "responded": False,
                "irrelevant_count": 0
            }

    elif mode == "constructive":
        explanation = generate_interactive_response([{"role": "user", "content": user_text}])
        followup = generate_constructive_prompt(user_text)
        response_text = f"{explanation}\n\n{followup}"
    else:
        response_text = "æœªçŸ¥æ¨¡å¼ï¼Œè«‹é‡æ–°é¸æ“‡ã€‚"
        
    line_bot_api.reply_message(event.reply_token, TextSendMessage(response_text))
    # å„²å­˜ä½¿ç”¨è€…è¼¸å…¥
    try:
        requests.post(f"{NODE_SERVER_URL}/save_message", json={
            "user_id": user_id,
            "message_text": user_text,
            "bot_response": "",  # ä½¿ç”¨è€…è¼¸å…¥ä¸åŒ…å« bot_response
            "message_type": "text"
        }, timeout=10)
        print(f"âœ… å„²å­˜ä½¿ç”¨è€…è¨Šæ¯: {user_text}")
    except requests.exceptions.RequestException as e:
        print(f"âŒ å„²å­˜ä½¿ç”¨è€…è¨Šæ¯å¤±æ•—: {e}")
    
    # å„²å­˜ AI å›è¦†
    if response_text.strip():
        try:
            requests.post(f"{NODE_SERVER_URL}/save_message", json={
                "user_id": user_id,
                "message_text": "",  # AI æ²’æœ‰ user text
                "bot_response": response_text,
                "message_type": "bot"
            }, timeout=10)
            print(f"âœ… å„²å­˜ AI å›è¦†: {response_text}")
        except requests.exceptions.RequestException as e:
            print(f"âŒ å„²å­˜ AI å›è¦†å¤±æ•—: {e}")


if __name__ == "__main__":
    port = int(os.environ.get('PORT', 5000))
    app.run(host='0.0.0.0', port=port)
