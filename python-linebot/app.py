from flask import Flask, request, abort, jsonify
from linebot import LineBotApi, WebhookHandler
from linebot.exceptions import InvalidSignatureError
from linebot.models import *
import os, openai
import requests
import time

app = Flask(__name__)
line_bot_api = LineBotApi(os.getenv('CHANNEL_ACCESS_TOKEN'))
handler = WebhookHandler(os.getenv('CHANNEL_SECRET'))
openai.api_key = os.getenv('OPENAI_API_KEY')
NODE_SERVER_URL = "https://node-mongo-b008.onrender.com"
user_mode = {}
user_state = {}  # user_id: { "mode": "active", "last_question": "...", "awaiting_answer": True }

def get_waiting_message(context):
    messages = {
        "answer_feedback": "ä¾†çœ‹çœ‹ä½ ç­”å¾—æ€éº¼æ¨£ ğŸ¤”",
        "explain_answer": "è®“æˆ‘æŸ¥æŸ¥æ­£ç¢ºç­”æ¡ˆæ˜¯ä»€éº¼ ğŸ§",
        "followup_concept": "å¥½å•é¡Œï¼Œæˆ‘ä¾†è§£é‡‹ä¸€ä¸‹ âœï¸",
        "next_question": "ç­‰æˆ‘ç”Ÿä¸€é¡Œæ–°çš„å‡ºä¾† ğŸ¯",
        "general_chat": "æˆ‘æƒ³æƒ³æ€éº¼èªªæ¯”è¼ƒå¥½ ğŸ¤”"
    }
    return messages.get(context, "ç¨ç­‰ä¸€ä¸‹ï¼Œæˆ‘æƒ³æƒ³çœ‹ ğŸ¤”")

def gpt_with_typing(context, user_id, reply_token, system_prompt, user_prompt):
    wait_msg = get_waiting_message(context)
    line_bot_api.reply_message(reply_token, TextSendMessage(text=wait_msg))

    response = openai.ChatCompletion.create(
        model="gpt-4o",
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt}
        ]
    )
    reply_text = response["choices"][0]["message"]["content"].strip()
    line_bot_api.push_message(user_id, TextSendMessage(text=reply_text))
    return reply_text

def load_history(user_id, retries=3, delay=3):
    url = f"{NODE_SERVER_URL}/get_history"
    for attempt in range(retries):
        try:
            response = requests.get(url, params={"user_id": user_id, "limit": 10}, timeout=30)
            response.raise_for_status()
            data = response.json()
            print(f"âœ… ç¬¬ {attempt+1} æ¬¡å˜—è©¦æˆåŠŸå–å¾—æ­·å²è¨Šæ¯")
            return data if "messages" in data else {"messages": []}
        except requests.exceptions.RequestException as e:
            print(f"âŒ API è®€å–å¤±æ•— ({attempt+1}/{retries}): {e}")
            if attempt < retries - 1:
                time.sleep(delay)
    print("âš ï¸ å¤šæ¬¡é‡è©¦å¾Œä»å¤±æ•—ï¼Œè¿”å›ç©ºæ­·å²è¨Šæ¯")
    return {"messages": []}

@app.route("/callback", methods=['POST'])
def callback():
    signature = request.headers.get('X-Line-Signature')
    if not signature:
        abort(403)

    body = request.get_data(as_text=True)
    print("ğŸ“¥ æ”¶åˆ° LINE Webhook:", body)

    try:
        handler.handle(body, signature)
    except InvalidSignatureError:
        print("âŒ LINE ç°½åé©—è­‰å¤±æ•—")
        abort(400)

    data = request.get_json(silent=True)
    if not data or "events" not in data:
        return jsonify({"error": "Invalid data"}), 400

    for event in data["events"]:
        if event["type"] == "message":
            message_data = {
                "user_id": event["source"].get("userId", "Unknown"),
                "message_text": event["message"].get("text", ""),
                "message_type": event["message"].get("type", "unknown")
            }
            print("ğŸ“© LINE è¨Šæ¯:", message_data)
    return 'OK'

def send_mode_selection(user_id):
    flex_message = FlexSendMessage(
        alt_text="è«‹é¸æ“‡å­¸ç¿’æ¨¡å¼",
        contents={
            "type": "bubble",
            "body": {
                "type": "box",
                "layout": "vertical",
                "contents": [
                    {"type": "text", "text": "è«‹é¸æ“‡å­¸ç¿’æ¨¡å¼", "weight": "bold", "size": "lg"},
                    {"type": "button", "style": "primary", "color": "#1DB446",
                     "action": {"type": "message", "label": "äº’å‹•å¼ (Interactive)", "text": "mode_interactive"}},
                    {"type": "button", "style": "primary", "color": "#FFB74D",
                     "action": {"type": "message", "label": "å»ºæ§‹å¼ (Constructive)", "text": "mode_constructive"}},
                    {"type": "button", "style": "primary", "color": "#42A5F5",
                     "action": {"type": "message", "label": "ä¸»å‹•å¼ (Active)", "text": "mode_active"}},
                    {"type": "button", "style": "primary", "color": "#9E9E9E",
                     "action": {"type": "message", "label": "è¢«å‹•å¼ (Passive)", "text": "mode_passive"}}
                ]
            }
        }
    )
    line_bot_api.push_message(user_id, flex_message)

def generate_active_question(level=1):
    system_message = (
        "ä½ æ˜¯ä¸€ä½ C èªè¨€æ•™å­¸åŠ©æ‰‹ï¼Œæœƒæ ¹æ“šé¡Œç›®é›£åº¦ç”¢ç”ŸæŒ‘æˆ°æ€§å•é¡Œã€‚\n"
        "Level 1ï¼šé¸æ“‡é¡Œï¼ˆç°¡å–®ï¼‰\n"
        "Level 2ï¼šå¡«ç©ºé¡Œï¼ˆä¸­ç­‰ï¼‰\n"
        "Level 3ï¼šç°¡ç­”é¡Œï¼ˆé€²éšï¼‰\n"
        "é€™äº›é›£åº¦è³‡è¨Šåªç”¨æ–¼å…§éƒ¨æ§åˆ¶ï¼Œè«‹å‹¿é¡¯ç¤ºçµ¦ä½¿ç”¨è€…ã€‚\n"
        "å‡ºé¡Œç¯„åœå¾ C èªè¨€åŸºæœ¬èªæ³•ã€è®Šæ•¸ã€æµç¨‹æ§åˆ¶ï¼Œåˆ°é€²éšå¦‚æŒ‡æ¨™èˆ‡è¿´åœˆã€‚"
    )

    user_prompt = (
        f"è«‹ç”¢ç”Ÿä¸€é¡Œ C èªè¨€çš„å•é¡Œï¼Œé›£åº¦ç‚º Level {level}ã€‚\n"
        "è«‹å¾é¸æ“‡é¡Œã€å¡«ç©ºé¡Œã€ç°¡ç­”é¡Œä¸­æ“‡ä¸€ç”¢ç”Ÿï¼Œå¹«åŠ©å­¸ç¿’è€…æ€è€ƒã€‚\n"
        "ä¸è¦æä¾›ç­”æ¡ˆã€‚"
    )

    response = openai.ChatCompletion.create(
        model="gpt-4o",
        messages=[
            {"role": "system", "content": system_message},
            {"role": "user", "content": user_prompt}
        ]
    )

    return response["choices"][0]["message"]["content"].strip()
@handler.add(MessageEvent, message=TextMessage)
def handle_message(event):
    user_id = event.source.user_id
    user_text = event.message.text.strip()
    print(f"ğŸ’¬ æ”¶åˆ°ä¾†è‡ª {user_id} çš„è¨Šæ¯: {user_text}")
    
    mode_map = {
        "mode_passive": "passive",
        "mode_active": "active",
        "mode_constructive": "constructive",
        "mode_interactive": "interactive"
    }

    if user_text in mode_map:
        user_mode[user_id] = mode_map[user_text]
    
        descriptions = {
            "passive": "ä½ æœƒä»¥é–±è®€ç‚ºä¸»ï¼Œæˆ‘æœƒç›¡é‡ç°¡æ½”åœ°å›ç­”ä½ ï¼Œä¸ä¸»å‹•æå•ã€‚",
            "active": "æˆ‘æœƒçµ¦ä½ ä¸€äº›æŒ‘æˆ°æ€§çš„å•é¡Œï¼Œè®“ä½ ä¸»å‹•æ€è€ƒå’Œä½œç­”ã€‚",
            "constructive": "æˆ‘æœƒæ ¹æ“šä½ çš„å›ç­”ï¼Œé€²ä¸€æ­¥è¿½å•ï¼Œå¹«åŠ©ä½ æ·±åŒ–æƒ³æ³•ã€‚",
            "interactive": "æˆ‘å€‘æœƒåƒæœ‹å‹ä¸€æ¨£å°è©±ï¼Œä¸€èµ·è¨è«–ä¸»é¡Œå’Œè§€é»ã€‚"
        }
    
        mode_key = mode_map[user_text]
        mode_name = user_text.replace("mode_", "").capitalize()
        description = descriptions[mode_key]
    
        if mode_key == "active":
            question = generate_active_question()
            user_state[user_id] = {
                "mode": "active",
                "last_question": question,
                "awaiting_answer": True
            }
            reply_text = f"âœ… å·²åˆ‡æ›è‡³ã€{mode_name}ã€æ¨¡å¼\n\n{description}\n\nç¬¬ä¸€é¡Œï¼š{question}\n\nä½ è¦ºå¾—ç­”æ¡ˆæ˜¯ä»€éº¼ï¼Ÿ"
        else:
            reply_text = f"âœ… å·²åˆ‡æ›è‡³ã€{mode_name}ã€æ¨¡å¼\n\n{description}"
    
        line_bot_api.reply_message(event.reply_token, TextSendMessage(reply_text))
        return

    mode = user_mode.get(user_id, "passive")
    print(f"ç”¨æˆ¶ {user_id} çš„ç›®å‰æ¨¡å¼ï¼š{mode}")

    history = load_history(user_id)
    messages = [{"role": "system", "content": "ä½ æ˜¯ä¸€å€‹æ™ºæ…§åŠ©ç†ï¼Œè«‹è¨˜ä½ä½¿ç”¨è€…çš„å°è©±æ­·å²ã€‚"}]
    
    for msg in sorted(history.get("messages", []), key=lambda x: x.get("timestamp", "")):
        if msg.get("message_text"):
            messages.append({"role": "user", "content": msg["message_text"]})
        elif msg.get("bot_response"):
            messages.append({"role": "assistant", "content": msg["bot_response"]})
    if mode == "passive":
        # è¢«å‹•æ¨¡å¼ï¼šä½¿ç”¨ gpt_with_typing å›è¦†
        response_text = gpt_with_typing(
            context="general_chat",
            user_id=user_id,
            reply_token=event.reply_token,
            system_prompt="ä½ æ˜¯ä¸€ä½å…·æœ‰æ­·å²è¨˜æ†¶çš„ C èªè¨€åŠ©æ•™ï¼Œè«‹ä»¥è‡ªç„¶æœ‰è€å¿ƒçš„æ–¹å¼å›æ‡‰ã€‚",
            user_prompt=user_text
        )

    elif mode == "interactive":
        recent = [
            msg for msg in messages
            if msg["role"] in ["user", "assistant"] and msg["content"].strip() not in ["", "è«‹é¸æ“‡å­¸ç¿’æ¨¡å¼"]
        ]
        short_history = recent[-3:]
        short_history.append({"role": "user", "content": user_text})

        joined_prompt = "\n".join([msg["content"] for msg in short_history])

        response_text = gpt_with_typing(
            context="general_chat",
            user_id=user_id,
            reply_token=event.reply_token,
            system_prompt="""
ä½ æ˜¯ä¸€ä½ç†±å¿ƒã€æœ‰è€å¿ƒçš„ C èªè¨€å­¸ç¿’å¤¥ä¼´ï¼Œæœƒç”¨è‡ªç„¶ã€å£èªçš„æ–¹å¼èˆ‡ä½¿ç”¨è€…äº’å‹•ã€‚
è«‹æ ¹æ“šä½¿ç”¨è€…ã€Œæœ€è¿‘çš„æå•å…§å®¹ã€ï¼Œåšå‡ºæ¸…æ¥šä½†è¼•é¬†çš„å›ç­”ã€‚
""",
            user_prompt=joined_prompt
        )

    elif mode == "constructive":
        explanation = gpt_with_typing(
            context="general_chat",
            user_id=user_id,
            reply_token=event.reply_token,
            system_prompt="ä½ æ˜¯ä¸€ä½ C èªè¨€åŠ©æ•™ï¼Œè«‹è‡ªç„¶åœ°è§£é‡‹ä»¥ä¸‹ä½¿ç”¨è€…èªªçš„å…§å®¹ï¼š",
            user_prompt=user_text
        )

        followup = gpt_with_typing(
            context="answer_feedback",
            user_id=user_id,
            reply_token=event.reply_token,
            system_prompt="ä½ æ˜¯ä¸€ä½æ“…é•·å¼•å°å­¸ç¿’çš„åŠ©æ•™ï¼Œè«‹æå‡ºä¸€å€‹æœ‰æ·±åº¦çš„è¿½å•ã€‚",
            user_prompt=f"é‡å°é€™æ®µå›æ‡‰ï¼šã€Œ{user_text}ã€ï¼Œè«‹æå‡ºä¸€å€‹è¿½å•ã€‚"
        )

        response_text = f"{explanation}\n\n{followup}"
    elif mode == "active":
        state = user_state.get(user_id, {})
        last_q = state.get("last_question")
        awaiting = state.get("awaiting_answer", False)
        level = state.get("difficulty_level", 1)

        def is_asking_for_answer(user_input):
            user_input = user_input.lower()
            return any(kw in user_input for kw in ["ç­”æ¡ˆ", "æ­£ç¢º", "è§£ç­”", "å‘Šè¨´æˆ‘"])

        def wants_next_question(user_input):
            user_input = user_input.lower()
            return any(kw in user_input for kw in ["ä¸‹ä¸€é¡Œ", "ä¸‹ä¸€å€‹", "å†ä¸€é¡Œ", "è«‹å†çµ¦ä¸€é¡Œ", "å†ä¾†", "ä¸‹ä¸€"])

        def is_answer_related(user_input, question):
            user_input = user_input.strip().lower()
            abcd_set = {"a", "b", "c", "d"}
            if user_input in abcd_set:
                return True
            if re.search(r"(é¸|ç­”æ¡ˆæ˜¯|æ‡‰è©²æ˜¯)[\s]*[a-d]", user_input):
                return True
            keywords = ["printf", "int", "æŒ‡æ¨™", "é™£åˆ—", "return", "è®Šæ•¸"]
            return any(kw in user_input for kw in keywords)

        def is_followup_question(user_input):
            user_input = user_input.lower()
            return any(kw in user_input for kw in ["ç‚ºä»€éº¼", "æ˜¯ä»€éº¼", "ä»£è¡¨", "å·®åˆ¥", "æ€éº¼", "å¦‚ä½•", "ä»€éº¼æ„æ€", "è·Ÿ", "æœ‰ä»€éº¼é—œä¿‚"])

        if awaiting and last_q:
            if is_asking_for_answer(user_text):
                response_text = gpt_with_typing(
                    context="explain_answer",
                    user_id=user_id,
                    reply_token=event.reply_token,
                    system_prompt="ä½ æ˜¯ä¸€ä½ C èªè¨€æ•™å­¸åŠ©ç†ï¼Œè«‹ç”¨ç°¡å–®æ–¹å¼æä¾›æ˜ç¢ºè§£ç­”ã€‚",
                    user_prompt=f"è«‹é‡å°ä»¥ä¸‹ C èªè¨€å•é¡Œçµ¦å‡ºç°¡å–®æ˜ç¢ºçš„è§£é‡‹èˆ‡ç­”æ¡ˆï¼š\n\nå•é¡Œï¼šã€Œ{last_q}ã€"
                )
                user_state[user_id].update({
                    "awaiting_answer": False,
                    "last_question": None,
                    "responded": False,
                    "irrelevant_count": 0
                })

            elif wants_next_question(user_text):
                question = generate_active_question(level=level)
                response_text = f"Level {level} æ–°æŒ‘æˆ°ä¾†å›‰ï¼\n\n{question}\n\nä½ è¦ºå¾—ç­”æ¡ˆæ˜¯ä»€éº¼ï¼Ÿ"
                line_bot_api.reply_message(event.reply_token, TextSendMessage(text=get_waiting_message("next_question")))
                line_bot_api.push_message(user_id, TextSendMessage(text=response_text))
                user_state[user_id].update({
                    "last_question": question,
                    "awaiting_answer": True,
                    "responded": False,
                    "irrelevant_count": 0
                })
                return

            elif is_answer_related(user_text, last_q):
                response_text = gpt_with_typing(
                    context="answer_feedback",
                    user_id=user_id,
                    reply_token=event.reply_token,
                    system_prompt="ä½ æ˜¯ä¸€ä½ C èªè¨€åŠ©æ•™ï¼Œè«‹é‡å°ä½¿ç”¨è€…çš„å›ç­”é€²è¡Œå»ºè¨­æ€§å›é¥‹ã€‚",
                    user_prompt=f"""ä»¥ä¸‹æ˜¯ä½ å…ˆå‰å•çš„ C èªè¨€å•é¡Œï¼š
ã€Œ{last_q}ã€

ä½¿ç”¨è€…å›è¦†ï¼šã€Œ{user_text}ã€

è«‹é‡å°ä»–çš„å›ç­”çµ¦å‡ºå›é¥‹ï¼ˆä¸çµ¦ç­”æ¡ˆï¼‰ï¼Œå¯é¼“å‹µã€ä¿®æ­£éŒ¯èª¤ã€å¼•å°æ€è€ƒã€‚"""
                )
                user_state[user_id]["responded"] = True
                user_state[user_id]["irrelevant_count"] = 0

                # è‡ªå‹•èª¿æ•´é›£åº¦
                if "ç­”å°" in response_text or "æ­£ç¢º" in response_text:
                    user_state[user_id]["difficulty_level"] = min(level + 1, 3)
                else:
                    user_state[user_id]["difficulty_level"] = max(level - 1, 1)

            elif is_followup_question(user_text):
                response_text = gpt_with_typing(
                    context="followup_concept",
                    user_id=user_id,
                    reply_token=event.reply_token,
                    system_prompt="ä½ æ˜¯ä¸€ä½ C èªè¨€åŠ©æ•™ï¼Œè«‹ç”¨é¼“å‹µä¸”æ¸…æ¥šçš„æ–¹å¼è§£é‡‹ä½¿ç”¨è€…å»¶ä¼¸è©¢å•çš„æ¦‚å¿µã€‚",
                    user_prompt=f"""ä½ æ˜¯ä¸€ä½ C èªè¨€æ•™å­¸åŠ©æ•™ã€‚
ç›®å‰ä½¿ç”¨è€…æ­£åœ¨å»¶ä¼¸å•èˆ‡é€™é¡Œæœ‰é—œçš„æ¦‚å¿µï¼šã€Œ{user_text}ã€
å•é¡Œæœ¬èº«æ˜¯ï¼šã€Œ{last_q}ã€
è«‹ç”¨ç°¡å–®æ¸…æ¥šçš„æ–¹å¼å›ç­”ä»–ï¼Œä¸è¦æä¾›åŸæœ¬å•é¡Œçš„æ­£ç¢ºè§£ç­”ï¼Œä¹Ÿä¸è¦å‡ºæ–°é¡Œã€‚"""
                )
                user_state[user_id]["irrelevant_count"] = 0

            else:
                count = user_state[user_id].get("irrelevant_count", 0) + 1
                user_state[user_id]["irrelevant_count"] = count

                if user_state[user_id].get("responded") and count >= 2:
                    question = generate_active_question(level=level)
                    response_text = f"çœ‹èµ·ä¾†é€™é¡Œä½ å·®ä¸å¤šäº†ï¼Œä¾†ä¸€é¡Œæ–°çš„å§ï¼š\n\n{question}\n\nä½ è¦ºå¾—ç­”æ¡ˆæ˜¯ä»€éº¼ï¼Ÿ"
                    line_bot_api.reply_message(event.reply_token, TextSendMessage(text=get_waiting_message("next_question")))
                    line_bot_api.push_message(user_id, TextSendMessage(text=response_text))
                    user_state[user_id].update({
                        "last_question": question,
                        "awaiting_answer": True,
                        "responded": False,
                        "irrelevant_count": 0
                    })
                    return
                else:
                    response_text = "æˆ‘è¨˜å¾—ä½ é‚„åœ¨é€™é¡Œå–”ï½æƒ³è½ç­”æ¡ˆå¯ä»¥å•æˆ‘ã€Œé€™é¡Œç­”æ¡ˆæ˜¯ä»€éº¼ï¼Ÿã€ï¼›æƒ³ä¸‹ä¸€é¡Œå¯ä»¥èªªã€Œä¸‹ä¸€é¡Œã€ï¼"
        else:
            question = generate_active_question(level=level)
            response_text = f"ä¾†æŒ‘æˆ°çœ‹çœ‹é€™é¡Œå§ï¼ˆLevel {level}ï¼‰ï¼š\n\n{question}\n\nä½ è¦ºå¾—ç­”æ¡ˆæ˜¯ä»€éº¼ï¼Ÿ"
            line_bot_api.reply_message(event.reply_token, TextSendMessage(text=get_waiting_message("next_question")))
            line_bot_api.push_message(user_id, TextSendMessage(text=response_text))
            user_state[user_id] = {
                "mode": "active",
                "last_question": question,
                "awaiting_answer": True,
                "responded": False,
                "irrelevant_count": 0,
                "difficulty_level": level
            }
            return
    # å„²å­˜ä½¿ç”¨è€…è¼¸å…¥
    try:
        requests.post(f"{NODE_SERVER_URL}/save_message", json={
            "user_id": user_id,
            "message_text": user_text,
            "bot_response": "",
            "message_type": "text"
        }, timeout=10)
        print(f"âœ… å„²å­˜ä½¿ç”¨è€…è¨Šæ¯: {user_text}")
    except requests.exceptions.RequestException as e:
        print(f"âŒ å„²å­˜ä½¿ç”¨è€…è¨Šæ¯å¤±æ•—: {e}")

    # å„²å­˜ AI å›è¦†
    if response_text.strip():
        try:
            requests.post(f"{NODE_SERVER_URL}/save_message", json={
                "user_id": user_id,
                "message_text": "",
                "bot_response": response_text,
                "message_type": "bot"
            }, timeout=10)
            print(f"âœ… å„²å­˜ AI å›è¦†: {response_text}")
        except requests.exceptions.RequestException as e:
            print(f"âŒ å„²å­˜ AI å›è¦†å¤±æ•—: {e}")

if __name__ == "__main__":
    port = int(os.environ.get('PORT', 5000))
    app.run(host='0.0.0.0', port=port)
